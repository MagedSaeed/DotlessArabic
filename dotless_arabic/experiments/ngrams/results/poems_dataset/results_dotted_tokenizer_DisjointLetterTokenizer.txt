####################################################################################################
Dotted Training Started at 2023-02-01 08:13:44.192314 for tokenizer: DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
اصبح الملك للذي فطر الخل ق بتقدير للعزيز العليم
غافر الذنب للمسيء بعفو قابل التوب ذي العطاء العميم
مرسل المصطفى البشير الينا رحمة منه بالكلام القديم
ربنا ربنا اليك انينا فاجرنا من حر نار الجحيم
واكفنا شر ما نخاف بلطف يا عظيما يرجى لكل عظيم
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
ا ##صبح ا ##لملك للذ ##ي فطر ا ##لخل ق بتقد ##ير للعز ##يز ا ##لعليم
غا ##فر ا ##لذ ##نب للمسيء بعفو قا ##بل ا ##لتو ##ب ذ ##ي ا ##لعطا ##ء ا ##لعميم
مر ##سل ا ##لمصطفى ا ##لبشير ا ##لينا ر ##حمة منه با ##لكلا ##م ا ##لقد ##يم
ر ##بنا ر ##بنا ا ##ليك ا ##نينا فا ##جر ##نا من حر نا ##ر ا ##لجحيم
و ##ا ##كفنا شر ما نخا ##ف بلطف يا عظيما ير ##جى لكل عظيم
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-poems_dataset": {
        "2": {
            "perplexity_with_OOVs": 122.22235133452288,
            "perplexity_without_OOVs": 120.06439509447972,
            "counts_of_OOVs": "8,717",
            "ngram_counts": "3,986,294"
        },
        "3": {
            "perplexity_with_OOVs": 72.07463378062877,
            "perplexity_without_OOVs": 70.7308668295224,
            "counts_of_OOVs": "8,717",
            "ngram_counts": "14,352,704"
        },
        "4": {
            "perplexity_with_OOVs": 50.757257478427874,
            "perplexity_without_OOVs": 49.78451378834047,
            "counts_of_OOVs": "8,717",
            "ngram_counts": "26,699,697"
        },
        "5": {
            "perplexity_with_OOVs": 40.53535948159189,
            "perplexity_without_OOVs": 39.747175144546624,
            "counts_of_OOVs": "8,717",
            "ngram_counts": "34,794,908"
        },
        "6": {
            "perplexity_with_OOVs": 36.22470476958431,
            "perplexity_without_OOVs": 35.516068650879255,
            "counts_of_OOVs": "8,717",
            "ngram_counts": "37,735,286"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer DisjointLetterTokenizer at 2023-02-01 08:21:08.686991
####################################################################################################
