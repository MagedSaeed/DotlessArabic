####################################################################################################
Undotted Training Started at 2023-09-23 00:05:52.152193 for tokenizer: DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
يتوضا ثلاثا يرفعه الى النبي صلى الله عليه وسلم
يغتسل من الجنابة ثم يجيء وله قفقفة فيستدفى بي ولم اغتسل
لا تبل قاىما فما بلت بعد قاىما
انت نهيت الناس ان يصلوا في نعالهم فقال لا لعمر الله ما نهيت الناس ان يصلوا في نعالهم غير اني ورب هذه الحرمة حتى قالها ثلاثا لقد رايت النبي صلى الله عليه وسلم ههنا عند المقام يصلي وعليه نعلاه ثم انصرف وهما عليه
ان انا صدقت فصدقني وان انا كذبت فكذبني قال فافعل قال فانشدك بالله هل سمعت رسول الله صلى الله عليه وسلم ينهى عن لبس الذهب قال نعم
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
ٮٮو صا <##> ٮلا ٮا <##> ٮر ڡعه <##> ا لى <##> ا لٮٮى <##> صلى <##> ا لله <##> علٮه <##> و سلم
ٮعٮسل <##> مں <##> ا لحٮا ٮه <##> ٮم <##> ٮحٮء <##> و له <##> ڡڡڡڡه <##> ڡٮسٮد ڡى <##> ٮى <##> و لم <##> ا عٮسل
لا <##> ٮٮل <##> ڡا ىما <##> ڡما <##> ٮلٮ <##> ٮعد <##> ڡا ىما
ا ٮٮ <##> ٮهٮٮ <##> ا لٮا س <##> ا ں <##> ٮصلو ا <##> ڡى <##> ٮعا لهم <##> ڡڡا ل <##> لا <##> لعمر <##> ا لله <##> ما <##> ٮهٮٮ <##> ا لٮا س <##> ا ں <##> ٮصلو ا <##> ڡى <##> ٮعا لهم <##> عٮر <##> ا ٮى <##> و ر ٮ <##> هد ه <##> ا لحر مه <##> حٮى <##> ڡا لها <##> ٮلا ٮا <##> لڡد <##> ر ا ٮٮ <##> ا لٮٮى <##> صلى <##> ا لله <##> علٮه <##> و سلم <##> ههٮا <##> عٮد <##> ا لمڡا م <##> ٮصلى <##> و علٮه <##> ٮعلا ه <##> ٮم <##> ا ٮصر ڡ <##> و هما <##> علٮه
ا ں <##> ا ٮا <##> صد ڡٮ <##> ڡصد ڡٮى <##> و ا ں <##> ا ٮا <##> كد ٮٮ <##> ڡكد ٮٮى <##> ڡا ل <##> ڡا ڡعل <##> ڡا ل <##> ڡا ٮسد ك <##> ٮا لله <##> هل <##> سمعٮ <##> ر سو ل <##> ا لله <##> صلى <##> ا لله <##> علٮه <##> و سلم <##> ٮٮهى <##> عں <##> لٮس <##> ا لد هٮ <##> ڡا ل <##> ٮعم
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "undotted-sanadset_hadeeth_dataset": {
        "2": {
            "perplexity_with_OOVs": 15.94481910546591,
            "perplexity_without_OOVs": 15.913037782462292,
            "counts_of_OOVs": "1,078",
            "ngram_counts": "169,573"
        },
        "3": {
            "perplexity_with_OOVs": 10.271185146416068,
            "perplexity_without_OOVs": 10.249961553644317,
            "counts_of_OOVs": "1,078",
            "ngram_counts": "1,075,006"
        },
        "4": {
            "perplexity_with_OOVs": 7.299708784938115,
            "perplexity_without_OOVs": 7.28418884119362,
            "counts_of_OOVs": "1,078",
            "ngram_counts": "3,414,550"
        },
        "5": {
            "perplexity_with_OOVs": 5.6350109472020655,
            "perplexity_without_OOVs": 5.622832403647828,
            "counts_of_OOVs": "1,078",
            "ngram_counts": "7,291,345"
        },
        "6": {
            "perplexity_with_OOVs": 4.497000736393358,
            "perplexity_without_OOVs": 4.487157228571572,
            "counts_of_OOVs": "1,078",
            "ngram_counts": "12,247,743"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer DisjointLetterTokenizer at 2023-09-23 00:14:15.277158
####################################################################################################
