####################################################################################################
Undotted Training Started at 2023-02-01 12:07:29.131369 for tokenizer: CharacterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
ى ##ٮ ##و ##ص ##ا ٮ ##ل ##ا ##ٮ ##ا ى ##ر ##ڡ ##ع ##ه ا ##ل ##ى ا ##ل ##ں ##ٮ ##ى ص ##ل ##ى ا ##ل ##ل ##ه ع ##ل ##ى ##ه و ##س ##ل ##م
ى ##ع ##ٮ ##س ##ل م ##ں ا ##ل ##ح ##ں ##ا ##ٮ ##ه ٮ ##م ى ##ح ##ى ##ء و ##ل ##ه ٯ ##ڡ ##ٯ ##ڡ ##ه ڡ ##ى ##س ##ٮ ##د ##ڡ ##ى ٮ ##ى و ##ل ##م ا ##ع ##ٮ ##س ##ل
ل ##ا ٮ ##ٮ ##ل ٯ ##ا ##ى ##م ##ا ڡ ##م ##ا ٮ ##ل ##ٮ ٮ ##ع ##د ٯ ##ا ##ى ##م ##ا
ا ##ں ##ٮ ں ##ه ##ى ##ٮ ا ##ل ##ں ##ا ##س ا ##ں ى ##ص ##ل ##و ##ا ڡ ##ى ں ##ع ##ا ##ل ##ه ##م ڡ ##ٯ ##ا ##ل ل ##ا ل ##ع ##م ##ر ا ##ل ##ل ##ه م ##ا ں ##ه ##ى ##ٮ ا ##ل ##ں ##ا ##س ا ##ں ى ##ص ##ل ##و ##ا ڡ ##ى ں ##ع ##ا ##ل ##ه ##م ع ##ى ##ر ا ##ں ##ى و ##ر ##ٮ ه ##د ##ه ا ##ل ##ح ##ر ##م ##ه ح ##ٮ ##ى ٯ ##ا ##ل ##ه ##ا ٮ ##ل ##ا ##ٮ ##ا ل ##ٯ ##د ر ##ا ##ى ##ٮ ا ##ل ##ں ##ٮ ##ى ص ##ل ##ى ا ##ل ##ل ##ه ع ##ل ##ى ##ه و ##س ##ل ##م ه ##ه ##ں ##ا ع ##ں ##د ا ##ل ##م ##ٯ ##ا ##م ى ##ص ##ل ##ى و ##ع ##ل ##ى ##ه ں ##ع ##ل ##ا ##ه ٮ ##م ا ##ں ##ص ##ر ##ڡ و ##ه ##م ##ا ع ##ل ##ى ##ه
ا ##ں ا ##ں ##ا ص ##د ##ٯ ##ٮ ڡ ##ص ##د ##ٯ ##ں ##ى و ##ا ##ں ا ##ں ##ا ك ##د ##ٮ ##ٮ ڡ ##ك ##د ##ٮ ##ں ##ى ٯ ##ا ##ل ڡ ##ا ##ڡ ##ع ##ل ٯ ##ا ##ل ڡ ##ا ##ں ##س ##د ##ك ٮ ##ا ##ل ##ل ##ه ه ##ل س ##م ##ع ##ٮ ر ##س ##و ##ل ا ##ل ##ل ##ه ص ##ل ##ى ا ##ل ##ل ##ه ع ##ل ##ى ##ه و ##س ##ل ##م ى ##ں ##ه ##ى ع ##ں ل ##ٮ ##س ا ##ل ##د ##ه ##ٮ ٯ ##ا ##ل ں ##ع ##م
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "undotted-sanadset_hadeeth_dataset": {
        "2": {
            "perplexity_with_OOVs": 15.221082918302352,
            "perplexity_without_OOVs": 15.221082918302352,
            "counts_of_OOVs": "0",
            "ngram_counts": "1,257"
        },
        "3": {
            "perplexity_with_OOVs": 8.969122897145544,
            "perplexity_without_OOVs": 8.969122897145544,
            "counts_of_OOVs": "0",
            "ngram_counts": "25,915"
        },
        "4": {
            "perplexity_with_OOVs": 6.181521501008943,
            "perplexity_without_OOVs": 6.181521501008943,
            "counts_of_OOVs": "0",
            "ngram_counts": "341,399"
        },
        "5": {
            "perplexity_with_OOVs": 4.834994030957346,
            "perplexity_without_OOVs": 4.834994030957346,
            "counts_of_OOVs": "0",
            "ngram_counts": "2,094,812"
        },
        "6": {
            "perplexity_with_OOVs": 3.930349077093587,
            "perplexity_without_OOVs": 3.930349077093587,
            "counts_of_OOVs": "0",
            "ngram_counts": "6,517,902"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer CharacterTokenizer at 2023-02-01 12:15:43.295267
####################################################################################################
