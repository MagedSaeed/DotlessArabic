####################################################################################################
Undotted Training Started at 2023-09-22 20:42:37.318665 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
يتوضا ثلاثا يرفعه الى النبي صلى الله عليه وسلم
يغتسل من الجنابة ثم يجيء وله قفقفة فيستدفى بي ولم اغتسل
لا تبل قاىما فما بلت بعد قاىما
انت نهيت الناس ان يصلوا في نعالهم فقال لا لعمر الله ما نهيت الناس ان يصلوا في نعالهم غير اني ورب هذه الحرمة حتى قالها ثلاثا لقد رايت النبي صلى الله عليه وسلم ههنا عند المقام يصلي وعليه نعلاه ثم انصرف وهما عليه
ان انا صدقت فصدقني وان انا كذبت فكذبني قال فافعل قال فانشدك بالله هل سمعت رسول الله صلى الله عليه وسلم ينهى عن لبس الذهب قال نعم
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
ٮٮوصا ٮلاٮا ٮرڡعه الى الٮٮى صلى الله علٮه وسلم
ٮعٮسل مں الحٮاٮه ٮم ٮحٮء وله ڡڡڡڡه ڡٮسٮدڡى ٮى ولم اعٮسل
لا ٮٮل ڡاىما ڡما ٮلٮ ٮعد ڡاىما
اٮٮ ٮهٮٮ الٮاس اں ٮصلوا ڡى ٮعالهم ڡڡال لا لعمر الله ما ٮهٮٮ الٮاس اں ٮصلوا ڡى ٮعالهم عٮر اٮى ورٮ هده الحرمه حٮى ڡالها ٮلاٮا لڡد راٮٮ الٮٮى صلى الله علٮه وسلم ههٮا عٮد المڡام ٮصلى وعلٮه ٮعلاه ٮم اٮصرڡ وهما علٮه
اں اٮا صدڡٮ ڡصدڡٮى واں اٮا كدٮٮ ڡكدٮٮى ڡال ڡاڡعل ڡال ڡاٮسدك ٮالله هل سمعٮ رسول الله صلى الله علٮه وسلم ٮٮهى عں لٮس الدهٮ ڡال ٮعم
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "undotted-sanadset_hadeeth_dataset": {
        "2": {
            "perplexity_with_OOVs": 140.9007709244586,
            "perplexity_without_OOVs": 136.1669331086009,
            "counts_of_OOVs": "8,619",
            "ngram_counts": "3,597,742"
        },
        "3": {
            "perplexity_with_OOVs": 39.277062545191924,
            "perplexity_without_OOVs": 37.840174484415606,
            "counts_of_OOVs": "8,619",
            "ngram_counts": "8,334,902"
        },
        "4": {
            "perplexity_with_OOVs": 26.467771511582992,
            "perplexity_without_OOVs": 25.477697368537335,
            "counts_of_OOVs": "8,619",
            "ngram_counts": "11,384,794"
        },
        "5": {
            "perplexity_with_OOVs": 23.83937685122159,
            "perplexity_without_OOVs": 22.942751885721286,
            "counts_of_OOVs": "8,619",
            "ngram_counts": "13,210,544"
        },
        "6": {
            "perplexity_with_OOVs": 23.0119858271179,
            "perplexity_without_OOVs": 22.14475829057324,
            "counts_of_OOVs": "8,619",
            "ngram_counts": "14,380,714"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer WordTokenizer at 2023-09-22 20:47:24.723764
####################################################################################################
