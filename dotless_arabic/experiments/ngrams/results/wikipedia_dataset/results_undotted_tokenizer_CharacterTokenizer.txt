####################################################################################################
Undotted Training Started at 2023-02-01 13:47:39.556026 for tokenizer: CharacterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
ل ##ك ##ل ##ى ##ه ##م ##ا م ##ع و ##ح ##و ##د ں ##س ##ٮ ##ه ص ##ع ##ى ##ر ##ه ع ##ل ##ى س ##ك ##ل ٮ ##ح ##ا ##ر م ##ا ##ء م ##ع ##ل ##ٯ ڡ ##ى ا ##ل ##ه ##و ##ا ##ء ع ##ل ##ى ه ##ى ##ى ##ه س ##ح ##ا ##ٮ ع ##ى ##و ##م و ##ا ##ح ##ى ##ا ##ں ##ا ا ##ح ##ر ##ى ع ##ل ##ى ه ##ى ##ى ##ه ص ##ٮ ##ا ##ٮ ا ##و ں ##د ##ى ٮ ##ا ##ل ##ا ##ص ##ا ##ڡ ##ه ا ##ل ##ى ا ##ل ##ر ##ح ##ا ##ٮ ا ##ل ##م ##ط ##ر ##ى ##ه ا ##و ا ##ل ##ٮ ##ل ##ح ##ى ##ه
ا ##م ##ا ڡ ##ى ا ##ل ##ط ##ٮ ##ى ##ع ##ه ڡ ##ٮ ##ٮ ##ع ##ى ##ر ح ##ا ##ل ##ه ا ##ل ##م ##ا ##ء ٮ ##ى ##ں ا ##ل ##ح ##ا ##ل ##ا ##ٮ ا ##ل ##ٮ ##ل ##ا ##ٮ ##ه ل ##ل ##م ##ا ##د ##ه ع ##ل ##ى س ##ط ##ح ا ##ل ##ا ##ر ##ص ٮ ##ا ##س ##ٮ ##م ##ر ##ا ##ر م ##ں ح ##ل ##ا ##ل م ##ا ى ##ع ##ر ##ڡ ٮ ##ا ##س ##م ا ##ل ##د ##و ##ر ##ه ا ##ل ##م ##ا ##ى ##ى ##ه ا ##و د ##و ##ر ##ه ا ##ل ##م ##ا ##ء و ##ا ##ل ##ٮ ##ى ٮ ##ٮ ##ص ##م ##ں ح ##د ##و ##ٮ ٮ ##ٮ ##ح ##ر و ##ں ##ٮ ##ح ں ##ٮ ##ح ٮ ##ٮ ##ح ##ر ##ى ٮ ##م ٮ ##ك ##ٮ ##ى ##ڡ ڡ ##ه ##ط ##و ##ل ٮ ##م ح ##ر ##ى ##ا ##ں ل ##ٮ ##ص ##ل ا ##ل ##ى ا ##ل ##م ##ص ##ٮ ڡ ##ى ا ##ل ##م ##س ##ط ##ح ##ا ##ٮ ا ##ل ##م ##ا ##ى ##ى ##ه
و ##ڡ ##ى ا ##ل ##ع ##ٯ ##و ##د ا ##ل ##ا ##ح ##ى ##ر ##ه س ##ح ##ل ##ٮ ح ##ا ##ل ##ا ##ٮ س ##ح ڡ ##ى ا ##ل ##م ##ى ##ا ##ه ا ##ل ##ع ##د ##ٮ ##ه ڡ ##ى م ##ں ##ا ##ط ##ٯ ع ##د ##ى ##د ##ه م ##ں ا ##ل ##ع ##ا ##ل ##م و ##ل ##ٯ ##د ٯ ##د ##ر ##ٮ ا ##ح ##ص ##ا ##ء ##ا ##ٮ ا ##ل ##ا ##م ##م ا ##ل ##م ##ٮ ##ح ##د ##ه ا ##ں ح ##و ##ا ##ل ##ى م ##ل ##ى ##ا ##ر س ##ح ##ص ع ##ل ##ى س ##ط ##ح ا ##ل ##ا ##ر ##ص ل ##ا ى ##ر ##ا ##ل ##و ##ں ى ##ڡ ##ٮ ##ٯ ##ر ##و ##ں ا ##ل ##و ##س ##ا ##ى ##ل ا ##ل ##م ##ٮ ##ا ##ح ##ه ل ##ل ##و ##ص ##و ##ل ا ##ل ##ى م ##ص ##د ##ر ا ##م ##ں ل ##م ##ى ##ا ##ه ا ##ل ##س ##ر ##ٮ و ##ا ##ں ح ##و ##ا ##ل ##ى
ط ##ه ##ر ڡ ##ى س ##ں ##ه ٮ ##ٯ ##ر ##ى ##ر ع ##ں ا ##ك ##ٮ ##س ##ا ##ڡ س ##ح ##ا ##ٮ ##ه ه ##ا ##ى ##ل ##ه م ##ں ٮ ##ح ##ا ##ر ا ##ل ##م ##ا ##ء ڡ ##ى ا ##ل ##ك ##و ##ں و ##ٮ ##ك ##م ##ى ##ا ##ٮ ٮ ##ڡ ##و ##ٯ ا ##ل ##ك ##م ##ى ##ه ا ##ل ##م ##و ##ح ##و ##د ##ه ع ##ل ##ى ا ##ل ##ا ##ر ##ص ٮ ٮ ##ر ##ى ##ل ##ى ##و ##ں م ##ر ##ه ڡ ##ى م ##ح ##ى ##ط ں ##ح ##م ر ##ا ##ى ##ڡ ى ##ٮ ##ع ##د ح ##و ##ا ##ل ##ى م ##ل ##ى ##ا ##ر س ##ں ##ه ص ##و ##ى ##ى ##ه ع ##ں ا ##ل ##ا ##ر ##ص
ى ##و ##ح ##د ا ##ل ##م ##ا ##ء ڡ ##ى ا ##ل ##ك ##و ##ں ع ##ل ##ى ا ##ل ##ع ##م ##و ##م ٮ ##ح ##ا ##ل ##ا ##ٮ ##ه ا ##ل ##ٮ ##ل ##ا ##ٮ ##ه ا ##ل ##ص ##ل ##ٮ ##ه و ##ا ##ل ##س ##ا ##ى ##ل ##ه و ##ا ##ل ##ع ##ا ##ر ##ى ##ه ٮ ##ا ##ل ##ا ##ص ##ا ##ڡ ##ه ل ##ا ##م ##ك ##ا ##ں ##ى ##ه ا ##ڡ ##ٮ ##ر ##ا ##ص ##ى ##ه ل ##و ##ح ##و ##د ##ه ع ##ل ##ى س ##ك ##ل ى ##د ##ع ##ى م ##ا ##ء ڡ ##ا ##ى ##ٯ ا ##ل ##ٮ ##ا ##ى ##ں ح ##ى ##ٮ ى ##ٮ ##ٮ ##ل ##و ##ر ا ##ل ##ا ##ك ##س ##ح ##ى ##ں و ##ٮ ##ٮ ##ٯ ##ى ا ##ى ##و ##ں ##ا ##ٮ ا ##ل ##ه ##ى ##د ##ر ##و ##ح ##ى ##ں ع ##ا ##ى ##م ##ه ٮ ##س ##ك ##ل ح ##ر د ##ا ##ح ##ل ا ##ل ##س ##ٮ ##ك ##ه ا ##ل ##ٮ ##ل ##و ##ر ##ى ##ه ل ##ل ##ا ##ك ##س ##ح ##ى ##ں
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "undotted-wikipedia_dataset": {
        "2": {
            "perplexity_with_OOVs": 15.778819708354943,
            "perplexity_without_OOVs": 15.778819708354943,
            "counts_of_OOVs": "0",
            "ngram_counts": "1,463"
        },
        "3": {
            "perplexity_with_OOVs": 11.578713907046907,
            "perplexity_without_OOVs": 11.578713907046907,
            "counts_of_OOVs": "0",
            "ngram_counts": "38,299"
        },
        "4": {
            "perplexity_with_OOVs": 8.121170448947998,
            "perplexity_without_OOVs": 8.121170448947998,
            "counts_of_OOVs": "0",
            "ngram_counts": "538,033"
        },
        "5": {
            "perplexity_with_OOVs": 6.350174039059506,
            "perplexity_without_OOVs": 6.350174039059506,
            "counts_of_OOVs": "0",
            "ngram_counts": "4,222,896"
        },
        "6": {
            "perplexity_with_OOVs": 5.541093935709163,
            "perplexity_without_OOVs": 5.541093935709163,
            "counts_of_OOVs": "0",
            "ngram_counts": "17,251,859"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer CharacterTokenizer at 2023-02-01 14:09:19.880956
####################################################################################################
