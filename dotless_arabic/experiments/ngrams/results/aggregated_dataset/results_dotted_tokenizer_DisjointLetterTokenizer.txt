####################################################################################################
Dotted Training Started at 2023-03-16 09:30:49.220318 for tokenizer: DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
بسم <##> ا لله <##> ا لر حمن <##> ا لر حيم
ا لحمد <##> لله <##> ر ب <##> ا لعا لمين
ا لر حمن <##> ا لر حيم
ما لك <##> يو م <##> ا لد ين
ا يا ك <##> نعبد <##> و ا يا ك <##> نستعين
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 25.93339076599771,
            "perplexity_without_OOVs": 25.863987445224076,
            "counts_of_OOVs": "12,980",
            "ngram_counts": "1,464,616"
        },
        "3": {
            "perplexity_with_OOVs": 16.4886984076784,
            "perplexity_without_OOVs": 16.442916005692638,
            "counts_of_OOVs": "12,980",
            "ngram_counts": "11,940,269"
        },
        "4": {
            "perplexity_with_OOVs": 12.170143641039829,
            "perplexity_without_OOVs": 12.135568512331435,
            "counts_of_OOVs": "12,980",
            "ngram_counts": "42,092,437"
        },
        "5": {
            "perplexity_with_OOVs": 9.66738476052486,
            "perplexity_without_OOVs": 9.63949697225651,
            "counts_of_OOVs": "12,980",
            "ngram_counts": "95,971,876"
        },
        "6": {
            "perplexity_with_OOVs": 8.25800621814378,
            "perplexity_without_OOVs": 8.233945111202921,
            "counts_of_OOVs": "12,980",
            "ngram_counts": "168,859,598"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer DisjointLetterTokenizer at 2023-03-16 10:08:24.152533
####################################################################################################
