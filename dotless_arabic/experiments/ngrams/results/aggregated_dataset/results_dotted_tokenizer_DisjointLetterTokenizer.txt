####################################################################################################
Dotted Training Started at 2023-09-23 02:03:07.284189 for tokenizer: DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
بسم <##> ا لله <##> ا لر حمن <##> ا لر حيم
ا لحمد <##> لله <##> ر ب <##> ا لعا لمين
ا لر حمن <##> ا لر حيم
ما لك <##> يو م <##> ا لد ين
ا يا ك <##> نعبد <##> و ا يا ك <##> نستعين
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 24.93267245031912,
            "perplexity_without_OOVs": 24.866601515757544,
            "counts_of_OOVs": "12,196",
            "ngram_counts": "1,323,871"
        },
        "3": {
            "perplexity_with_OOVs": 15.784127547197771,
            "perplexity_without_OOVs": 15.74056454608149,
            "counts_of_OOVs": "12,196",
            "ngram_counts": "11,147,001"
        },
        "4": {
            "perplexity_with_OOVs": 11.64072459842004,
            "perplexity_without_OOVs": 11.607821697069753,
            "counts_of_OOVs": "12,196",
            "ngram_counts": "39,565,800"
        },
        "5": {
            "perplexity_with_OOVs": 9.288109974791169,
            "perplexity_without_OOVs": 9.261458019303433,
            "counts_of_OOVs": "12,196",
            "ngram_counts": "90,803,751"
        },
        "6": {
            "perplexity_with_OOVs": 7.999309222689188,
            "perplexity_without_OOVs": 7.976137603752285,
            "counts_of_OOVs": "12,196",
            "ngram_counts": "161,152,258"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer DisjointLetterTokenizer at 2023-09-23 02:39:14.746684
####################################################################################################
