####################################################################################################
Dotted Training Started at 2023-02-01 10:05:52.338551 for tokenizer: DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم ا ##لله ا ##لر ##حمن ا ##لر ##حيم
ا ##لحمد لله ر ##ب ا ##لعا ##لمين
ا ##لر ##حمن ا ##لر ##حيم
ما ##لك يو ##م ا ##لد ##ين
ا ##يا ##ك نعبد و ##ا ##يا ##ك نستعين
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 68.09100218982807,
            "perplexity_without_OOVs": 67.79277840858629,
            "counts_of_OOVs": "16,002",
            "ngram_counts": "10,952,071"
        },
        "3": {
            "perplexity_with_OOVs": 33.53805058696297,
            "perplexity_without_OOVs": 33.38327722879296,
            "counts_of_OOVs": "16,002",
            "ngram_counts": "50,174,786"
        },
        "4": {
            "perplexity_with_OOVs": 21.929645323667312,
            "perplexity_without_OOVs": 21.825799832357948,
            "counts_of_OOVs": "16,002",
            "ngram_counts": "119,097,931"
        },
        "5": {
            "perplexity_with_OOVs": 17.333072932992877,
            "perplexity_without_OOVs": 17.24993324357591,
            "counts_of_OOVs": "16,002",
            "ngram_counts": "197,449,833"
        },
        "6": {
            "perplexity_with_OOVs": 15.43256794267123,
            "perplexity_without_OOVs": 15.358140005153468,
            "counts_of_OOVs": "16,002",
            "ngram_counts": "265,881,811"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer DisjointLetterTokenizer at 2023-02-01 10:54:02.600459
####################################################################################################
