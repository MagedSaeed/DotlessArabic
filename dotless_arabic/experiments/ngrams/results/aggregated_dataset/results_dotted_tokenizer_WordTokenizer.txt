####################################################################################################
Dotted Training Started at 2023-03-29 05:16:06.283577 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 1023.8094799906223,
            "perplexity_without_OOVs": 978.3624074368606,
            "counts_of_OOVs": "97,953",
            "ngram_counts": "55,161,841"
        },
        "3": {
            "perplexity_with_OOVs": 472.1159796918054,
            "perplexity_without_OOVs": 449.92632380284965,
            "counts_of_OOVs": "97,953",
            "ngram_counts": "133,569,984"
        },
        "4": {
            "perplexity_with_OOVs": 384.18972515126165,
            "perplexity_without_OOVs": 365.89923415858203,
            "counts_of_OOVs": "97,953",
            "ngram_counts": "171,414,826"
        },
        "5": {
            "perplexity_with_OOVs": 366.3754661412316,
            "perplexity_without_OOVs": 348.88616118562686,
            "counts_of_OOVs": "97,953",
            "ngram_counts": "181,415,807"
        },
        "6": {
            "perplexity_with_OOVs": 362.0625584074154,
            "perplexity_without_OOVs": 344.7684295694556,
            "counts_of_OOVs": "97,953",
            "ngram_counts": "180,941,159"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer WordTokenizer at 2023-03-29 06:01:23.375529
####################################################################################################
