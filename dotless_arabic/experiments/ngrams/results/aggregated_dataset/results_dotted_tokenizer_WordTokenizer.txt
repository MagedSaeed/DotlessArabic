####################################################################################################
Dotted Training Started at 2023-03-16 05:46:51.713679 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 1026.8054685958596,
            "perplexity_without_OOVs": 981.0818388865086,
            "counts_of_OOVs": "98,353",
            "ngram_counts": "55,149,122"
        },
        "3": {
            "perplexity_with_OOVs": 473.8177377203286,
            "perplexity_without_OOVs": 451.4792349222018,
            "counts_of_OOVs": "98,353",
            "ngram_counts": "133,544,042"
        },
        "4": {
            "perplexity_with_OOVs": 385.7599853325726,
            "perplexity_without_OOVs": 367.3384063021102,
            "counts_of_OOVs": "98,353",
            "ngram_counts": "171,388,600"
        },
        "5": {
            "perplexity_with_OOVs": 367.92745862633757,
            "perplexity_without_OOVs": 350.3108983832005,
            "counts_of_OOVs": "98,353",
            "ngram_counts": "181,391,295"
        },
        "6": {
            "perplexity_with_OOVs": 363.6146910518704,
            "perplexity_without_OOVs": 346.1938237767102,
            "counts_of_OOVs": "98,353",
            "ngram_counts": "180,916,887"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer WordTokenizer at 2023-03-16 06:32:07.308051
####################################################################################################
