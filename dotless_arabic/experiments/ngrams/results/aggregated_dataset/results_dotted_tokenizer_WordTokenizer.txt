####################################################################################################
Dotted Training Started at 2023-09-22 22:19:53.476458 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 980.0754038912521,
            "perplexity_without_OOVs": 935.9102814941438,
            "counts_of_OOVs": "94,216",
            "ngram_counts": "52,259,678"
        },
        "3": {
            "perplexity_with_OOVs": 482.42696270248615,
            "perplexity_without_OOVs": 459.5474533055958,
            "counts_of_OOVs": "94,216",
            "ngram_counts": "127,370,964"
        },
        "4": {
            "perplexity_with_OOVs": 400.594067661588,
            "perplexity_without_OOVs": 381.3748231419617,
            "counts_of_OOVs": "94,216",
            "ngram_counts": "165,730,850"
        },
        "5": {
            "perplexity_with_OOVs": 382.3135342413787,
            "perplexity_without_OOVs": 363.92179810638777,
            "counts_of_OOVs": "94,216",
            "ngram_counts": "177,565,146"
        },
        "6": {
            "perplexity_with_OOVs": 377.64994307062545,
            "perplexity_without_OOVs": 359.4701330603785,
            "counts_of_OOVs": "94,216",
            "ngram_counts": "179,148,679"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer WordTokenizer at 2023-09-22 23:05:29.321339
####################################################################################################
