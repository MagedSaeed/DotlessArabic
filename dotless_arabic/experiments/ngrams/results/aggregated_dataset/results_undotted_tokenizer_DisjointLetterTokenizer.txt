####################################################################################################
Undotted Training Started at 2023-02-06 07:28:18.183493 for tokenizer: DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
ٮسم <##> ا لله <##> ا لر حمں <##> ا لر حىم
ا لحمد <##> لله <##> ر ٮ <##> ا لعا لمىں
ا لر حمں <##> ا لر حىم
ما لك <##> ىو م <##> ا لد ىں
ا ىا ك <##> ٮعٮد <##> و ا ىا ك <##> ٮسٮعىں
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "undotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 23.850936105606635,
            "perplexity_without_OOVs": 23.820197400872647,
            "counts_of_OOVs": "6,254",
            "ngram_counts": "901,820"
        },
        "3": {
            "perplexity_with_OOVs": 16.192872730731903,
            "perplexity_without_OOVs": 16.1712279645914,
            "counts_of_OOVs": "6,254",
            "ngram_counts": "8,505,282"
        },
        "4": {
            "perplexity_with_OOVs": 12.296016302443904,
            "perplexity_without_OOVs": 12.279188523182807,
            "counts_of_OOVs": "6,254",
            "ngram_counts": "33,539,801"
        },
        "5": {
            "perplexity_with_OOVs": 9.788709417333447,
            "perplexity_without_OOVs": 9.775094945614637,
            "counts_of_OOVs": "6,254",
            "ngram_counts": "83,356,482"
        },
        "6": {
            "perplexity_with_OOVs": 8.272849624303678,
            "perplexity_without_OOVs": 8.261206810668368,
            "counts_of_OOVs": "6,254",
            "ngram_counts": "155,573,447"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer DisjointLetterTokenizer at 2023-02-06 08:47:04.220686
####################################################################################################
