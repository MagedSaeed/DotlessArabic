####################################################################################################
Undotted Training Started at 2023-03-29 06:01:23.375752 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
ٮسم الله الرحمں الرحٮم
الحمد لله رٮ العالمٮں
الرحمں الرحٮم
مالك ٮوم الدٮں
اٮاك ٮعٮد واٮاك ٮسٮعٮں
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "undotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 965.9728752018079,
            "perplexity_without_OOVs": 938.3706102571084,
            "counts_of_OOVs": "62,272",
            "ngram_counts": "51,591,815"
        },
        "3": {
            "perplexity_with_OOVs": 434.7818767267026,
            "perplexity_without_OOVs": 421.59379829967344,
            "counts_of_OOVs": "62,272",
            "ngram_counts": "131,779,360"
        },
        "4": {
            "perplexity_with_OOVs": 349.163092295245,
            "perplexity_without_OOVs": 338.4248553194291,
            "counts_of_OOVs": "62,272",
            "ngram_counts": "170,732,718"
        },
        "5": {
            "perplexity_with_OOVs": 332.31413421938834,
            "perplexity_without_OOVs": 322.0654044131354,
            "counts_of_OOVs": "62,272",
            "ngram_counts": "181,065,851"
        },
        "6": {
            "perplexity_with_OOVs": 328.2931156491222,
            "perplexity_without_OOVs": 318.16196464766523,
            "counts_of_OOVs": "62,272",
            "ngram_counts": "180,690,489"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer WordTokenizer at 2023-03-29 06:56:35.178569
####################################################################################################
