####################################################################################################
Undotted Training Started at 2023-03-16 06:32:07.308907 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
ٮسم الله الرحمں الرحىم
الحمد لله رٮ العالمىں
الرحمں الرحىم
مالك ىوم الدىں
اىاك ٮعٮد واىاك ٮسٮعىں
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "undotted-aggregated_dataset": {
        "2": {
            "perplexity_with_OOVs": 994.4681394471663,
            "perplexity_without_OOVs": 962.1566548116305,
            "counts_of_OOVs": "71,085",
            "ngram_counts": "52,921,951"
        },
        "3": {
            "perplexity_with_OOVs": 449.98746030677836,
            "perplexity_without_OOVs": 434.4759839913532,
            "counts_of_OOVs": "71,085",
            "ngram_counts": "132,584,306"
        },
        "4": {
            "perplexity_with_OOVs": 363.1904764654303,
            "perplexity_without_OOVs": 350.50130912025435,
            "counts_of_OOVs": "71,085",
            "ngram_counts": "171,023,887"
        },
        "5": {
            "perplexity_with_OOVs": 346.02581767158597,
            "perplexity_without_OOVs": 333.9038903724656,
            "counts_of_OOVs": "71,085",
            "ngram_counts": "181,172,899"
        },
        "6": {
            "perplexity_with_OOVs": 341.91188448794594,
            "perplexity_without_OOVs": 329.92650526722224,
            "counts_of_OOVs": "71,085",
            "ngram_counts": "180,741,502"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer WordTokenizer at 2023-03-16 07:25:38.885572
####################################################################################################
