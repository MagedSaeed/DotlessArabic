####################################################################################################
Undotted Training Started at 2023-03-29 03:29:18.562091 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
ٮسم الله الرحمں الرحٮم
الحمد لله رٮ العالمٮں
الرحمں الرحٮم
مالك ٮوم الدٮں
اٮاك ٮعٮد واٮاك ٮسٮعٮں
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "undotted-quran_dataset": {
        "2": {
            "perplexity_with_OOVs": 344.88387945983715,
            "perplexity_without_OOVs": 196.77797706566497,
            "counts_of_OOVs": "786",
            "ngram_counts": "43,068"
        },
        "3": {
            "perplexity_with_OOVs": 254.02952645618768,
            "perplexity_without_OOVs": 141.31459348470673,
            "counts_of_OOVs": "786",
            "ngram_counts": "55,315"
        },
        "4": {
            "perplexity_with_OOVs": 246.5144408429652,
            "perplexity_without_OOVs": 136.90674354570015,
            "counts_of_OOVs": "786",
            "ngram_counts": "56,689"
        },
        "5": {
            "perplexity_with_OOVs": 246.72683175878385,
            "perplexity_without_OOVs": 137.10773662307633,
            "counts_of_OOVs": "786",
            "ngram_counts": "54,431"
        },
        "6": {
            "perplexity_with_OOVs": 247.24033093739007,
            "perplexity_without_OOVs": 137.4351142870473,
            "counts_of_OOVs": "786",
            "ngram_counts": "50,806"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer WordTokenizer at 2023-03-29 03:29:53.565495
####################################################################################################
