####################################################################################################
Dotted Training Started at 2023-03-29 06:56:37.075255 for tokenizer: DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after tokenization:
بسم <##> ا لله <##> ا لر حمن <##> ا لر حيم
ا لحمد <##> لله <##> ر ب <##> ا لعا لمين
ا لر حمن <##> ا لر حيم
ما لك <##> يو م <##> ا لد ين
ا يا ك <##> نعبد <##> و ا يا ك <##> نستعين
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-quran_dataset": {
        "2": {
            "perplexity_with_OOVs": 20.29134437744725,
            "perplexity_without_OOVs": 18.09915247289703,
            "counts_of_OOVs": "287",
            "ngram_counts": "19,397"
        },
        "3": {
            "perplexity_with_OOVs": 13.559528030732992,
            "perplexity_without_OOVs": 12.025781633812198,
            "counts_of_OOVs": "287",
            "ngram_counts": "46,224"
        },
        "4": {
            "perplexity_with_OOVs": 10.816756148464146,
            "perplexity_without_OOVs": 9.565645086788516,
            "counts_of_OOVs": "287",
            "ngram_counts": "78,640"
        },
        "5": {
            "perplexity_with_OOVs": 9.672516811649512,
            "perplexity_without_OOVs": 8.54402979792689,
            "counts_of_OOVs": "287",
            "ngram_counts": "106,413"
        },
        "6": {
            "perplexity_with_OOVs": 9.109045407193081,
            "perplexity_without_OOVs": 8.042402628006966,
            "counts_of_OOVs": "287",
            "ngram_counts": "125,880"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer DisjointLetterTokenizer at 2023-03-29 06:57:11.462090
####################################################################################################
