####################################################################################################
Dotted Training Started at 2023-02-01 04:33:11.095719 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before tokenization:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Tokenize the dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
TRAINING STARTED
####################################################################################################
####################################################################################################
{
    "dotted-quran_dataset": {
        "2": {
            "perplexity_with_OOVs": 369.2976458925257,
            "perplexity_without_OOVs": 192.1547755088095,
            "counts_of_OOVs": "910",
            "ngram_counts": "43,722"
        },
        "3": {
            "perplexity_with_OOVs": 274.6400408137596,
            "perplexity_without_OOVs": 138.73698455561484,
            "counts_of_OOVs": "910",
            "ngram_counts": "55,526"
        },
        "4": {
            "perplexity_with_OOVs": 266.9026750328824,
            "perplexity_without_OOVs": 134.59894077235214,
            "counts_of_OOVs": "910",
            "ngram_counts": "56,779"
        },
        "5": {
            "perplexity_with_OOVs": 267.0623807032808,
            "perplexity_without_OOVs": 134.77547335540686,
            "counts_of_OOVs": "910",
            "ngram_counts": "54,470"
        },
        "6": {
            "perplexity_with_OOVs": 267.5737684308006,
            "perplexity_without_OOVs": 135.07796790136203,
            "counts_of_OOVs": "910",
            "ngram_counts": "50,819"
        }
    }
}
####################################################################################################
####################################################################################################
TRAINING FINISHED
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer WordTokenizer at 2023-02-01 04:33:38.341637
####################################################################################################
