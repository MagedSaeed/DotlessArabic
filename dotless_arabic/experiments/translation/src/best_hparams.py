best_params = {
    # "sanad": {
    #     "WordTokenizer": dict(
    #         rnn_hiddens=512,
    #         rnn_dropout=0.5,
    #         dropout_prob=0.5,
    #         embedding_size=128,
    #         learning_rate=0.001,
    #     ),
    # "FarasaMorphologicalTokenizer": dict(
    #     num_layers=2,
    #     learning_rate=0.001,
    #     hidden_size=256,
    #     embedding_size=512,
    #     dropout_prop=0.2,
    # ),
    # "DisjointLetterTokenizer": dict(
    #     num_layers=2,
    #     learning_rate=0.001,
    #     hidden_size=256,
    #     embedding_size=512,
    #     dropout_prop=0.2,
    # ),
    # "CharacterTokenizer": dict(
    #     num_layers=2,
    #     learning_rate=0.001,
    #     hidden_size=256,
    #     embedding_size=512,
    #     dropout_prop=0.2,
    # ),
    # },
}
