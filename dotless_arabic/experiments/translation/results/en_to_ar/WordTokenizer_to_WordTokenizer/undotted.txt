####################################################################################################
Undotted Training Started at 2023-10-14 16:29:58.495591 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Collecting dataset splits:
####################################################################################################
####################################################################################################
Processing source and target sequences:
####################################################################################################
####################################################################################################
Segmenting english with moses:
####################################################################################################
####################################################################################################
Undot text
####################################################################################################
####################################################################################################
Building source and target tokenizers
####################################################################################################
####################################################################################################
Source vocab size: 60207
Target vocab size: 136673
####################################################################################################
####################################################################################################
Calculate sequence length:
####################################################################################################
####################################################################################################
Source Max Doc Length: 41
Target Max Doc Length: 33
####################################################################################################
####################################################################################################
Building DataLoaders
####################################################################################################
####################################################################################################
Train DataLoader: 3,621
Val DataLoader: 14
Test DataLoader: 135
####################################################################################################
####################################################################################################
| Name                | Type               | Params
-----------------------------------------------------------
0 | transformer         | Transformer        | 2.5 M
1 | src_tok_emb         | TokenEmbedding     | 7.7 M
2 | tgt_tok_emb         | TokenEmbedding     | 17.5 M
3 | positional_encoding | PositionalEncoding | 0
4 | dense               | Linear             | 17.6 M
-----------------------------------------------------------
45.3 M    Trainable params
0         Non-trainable params
45.3 M    Total params
181.347   Total estimated model params size (MB)
####################################################################################################
####################################################################################################
Training Time: 0.00 seconds
####################################################################################################
####################################################################################################
Average training Time for one epoch: 0.000 seconds
####################################################################################################
####################################################################################################
Losses: [
{
"test_loss/dataloader_idx_0": 4.661401271820068
},
{
"test_loss/dataloader_idx_1": 6.074053764343262
},
{
"test_loss/dataloader_idx_2": 5.937140941619873
}
]
####################################################################################################
####################################################################################################
Test blue score (sacre): 0.12814441323280334
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer WordTokenizer at 2023-10-14 18:10:20.535780
####################################################################################################
