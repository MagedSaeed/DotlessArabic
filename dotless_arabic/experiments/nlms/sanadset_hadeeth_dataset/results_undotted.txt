################################################################################
Undotted Training Started
################################################################################
################################################################################
Some of the Dataset Samples after undotting:
ىٮوصا ٮلاٮا ىرڡعه الى الٮٮى صلى الله علىه وسلم
ىعٮسل مں الحٮاٮه ٮم ىحىء وله ڡڡڡڡه ڡىسٮدڡى ٮى ولم اعٮسل
لا ٮٮل ڡاىما ڡما ٮلٮ ٮعد ڡاىما
اٮٮ ٮهىٮ الٮاس اں ىصلوا ڡى ٮعالهم ڡڡال لا لعمر الله ما ٮهىٮ الٮاس اں ىصلوا ڡى ٮعالهم عىر اٮى ورٮ هده الحرمه حٮى ڡالها ٮلاٮا لڡد راىٮ الٮٮى صلى الله علىه وسلم ههٮا عٮد المڡام ىصلى وعلىه ٮعلاه ٮم اٮصرڡ وهما علىه
اں اٮا صدڡٮ ڡصدڡٮى واں اٮا كدٮٮ ڡكدٮٮى ڡال ڡاڡعل ڡال ڡاٮسدك ٮالله هل سمعٮ رسول الله صلى الله علىه وسلم ىٮهى عں لٮس الدهٮ ڡال ٮعم
################################################################################
################################################################################
Train Samples: 746,477
Val Samples: 7,541
Test Samples: 83,780
################################################################################
################################################################################
Considered Vocab: 10,725
All Vocab: 243,906
################################################################################
################################################################################
Tokenizer Vocab Size (to make sure): 10,725
################################################################################
################################################################################
Sequence Length: 36
################################################################################
################################################################################
Train DataLoader: 2,914
Val DataLoader: 29
Test DataLoader: 327
################################################################################
################################################################################
| Name               | Type      | Params
-------------------------------------------------
0 | embedding_layer    | Embedding | 4.3 M
1 | gru_layer          | GRU       | 2.9 M
2 | first_dense_layer  | Linear    | 160 K
3 | dropout_layer      | Dropout   | 0
4 | relu               | ReLU      | 0
5 | second_dense_layer | Linear    | 4.3 M
-------------------------------------------------
11.6 M    Trainable params
0         Non-trainable params
11.6 M    Total params
46.553    Total estimated model params size (MB)
################################################################################
################################################################################
Training Perplexity: 19.282282307976285
Perplexity with OOVs: 24.446154843699183
Perplexity without OOVs: 28.09305376569249
################################################################################
################################################################################
Training Time: 3720.88 seconds
################################################################################
################################################################################
<bos>  ڡال ڡال رسول الله <eos>
ڡال ڡال رسول الله <eos>
################################################################################
################################################################################
Undotted Training Finished
################################################################################
