####################################################################################################
Undotted Training Started at 2023-02-01 03:57:09.944241 for tokenizer: WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
اصٮح الملك للدى ڡطر الحل ٯ ٮٮڡدىر للعرىر العلىم
عاڡر الدٮٮ للمسىء ٮعڡو ڡاٮل الٮوٮ دى العطاء العمىم
مرسل المصطڡى الٮسىر الىٮا رحمه مٮه ٮالكلام الڡدىم
رٮٮا رٮٮا الىك اٮىٮا ڡاحرٮا مں حر ٮار الححىم
واكڡٮا سر ما ٮحاڡ ٮلطڡ ىا عطىما ىرحى لكل عطىم
####################################################################################################
####################################################################################################
Train Samples: 2,741,557
Val Samples: 144,293
Test Samples: 320,650
####################################################################################################
####################################################################################################
Considered Vocab: 130,152
All Vocab: 628,842
####################################################################################################
####################################################################################################
Tokenizer Vocab Size (to make sure): 130,152
####################################################################################################
####################################################################################################
Sequence Length: 20
####################################################################################################
####################################################################################################
Train DataLoader: 10,709
Val DataLoader: 563
Test DataLoader: 1,252
####################################################################################################
####################################################################################################
| Name               | Type      | Params
-------------------------------------------------
0 | embedding_layer    | Embedding | 66.6 M
1 | gru_layer          | GRU       | 6.3 M
2 | first_dense_layer  | Linear    | 262 K
3 | dropout_layer      | Dropout   | 0
4 | relu               | ReLU      | 0
5 | second_dense_layer | Linear    | 66.8 M
-------------------------------------------------
139 M     Trainable params
0         Non-trainable params
139 M     Total params
559.889   Total estimated model params size (MB)
####################################################################################################
####################################################################################################
Training Perplexity: 1626.2549183641174
Perplexity with OOVs: 2286.086228058237
Perplexity without OOVs: 3,027.8745510585536
####################################################################################################
####################################################################################################
Training OOVs rate: 5.00
Validation OOVs rate: 5.00
Test OOVs rate: 5.00
####################################################################################################
####################################################################################################
Training Time: 92463.53 seconds
####################################################################################################
####################################################################################################
<bos> ڡى عىٮىك ڡى عىٮىك مں رحمه ما عاد مں هوى
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer WordTokenizer at 2023-02-02 05:57:13.885143
####################################################################################################
