####################################################################################################
Undotted Training Started at 2023-09-29 17:56:03.464540 for tokenizer: FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
يتوضا ثلاثا يرفعه الى النبي صلى الله عليه وسلم
يغتسل من الجنابة ثم يجيء وله قفقفة فيستدفى بي ولم اغتسل
لا تبل قاىما فما بلت بعد قاىما
انت نهيت الناس ان يصلوا في نعالهم فقال لا لعمر الله ما نهيت الناس ان يصلوا في نعالهم غير اني ورب هذه الحرمة حتى قالها ثلاثا لقد رايت النبي صلى الله عليه وسلم ههنا عند المقام يصلي وعليه نعلاه ثم انصرف وهما عليه
ان انا صدقت فصدقني وان انا كذبت فكذبني قال فافعل قال فانشدك بالله هل سمعت رسول الله صلى الله عليه وسلم ينهى عن لبس الذهب قال نعم
####################################################################################################
####################################################################################################
Train Samples: 716,317
Val Samples: 37,701
Test Samples: 83,780
####################################################################################################
####################################################################################################
Calculating vocab size using WordTokenizer:
####################################################################################################
####################################################################################################
Considered Vocab (from WordTokenizer): 23,291
All Vocab (WordTokenizer): 215,762
####################################################################################################
####################################################################################################
Tokenizer Vocab Size: 12,019
####################################################################################################
####################################################################################################
Calculating Sequence Length:
####################################################################################################
####################################################################################################
Sequence Length: 325
####################################################################################################
####################################################################################################
Getting Vocab counts
####################################################################################################
####################################################################################################
train vocab count: 299,162
train tokens count: 24,679,548
----------------------------------------
val vocab count: 81,763
val tokens count: 1,295,878
----------------------------------------
test vocab count: 121,488
test tokens count: 2,905,392
----------------------------------------
####################################################################################################
####################################################################################################
Building DataLoaders
####################################################################################################
####################################################################################################
Train DataLoader: 11,187
Val DataLoader: 588
Test DataLoader: 1,308
####################################################################################################
####################################################################################################
| Name               | Type       | Params
--------------------------------------------------
0 | embedding_layer    | Embedding  | 6.2 M
1 | rnn                | GRU        | 3.2 M
2 | dropout_layer      | Dropout    | 0
3 | relu               | LeakyReLU  | 0
4 | first_dense_layer  | Linear     | 262 K
5 | second_dense_layer | Linear     | 6.2 M
6 | train_ppl          | Perplexity | 0
7 | val_ppl            | Perplexity | 0
8 | test_ppl           | Perplexity | 0
--------------------------------------------------
9.6 M     Trainable params
0         Non-trainable params
9.6 M     Total params
38.321    Total estimated model params size (MB)
####################################################################################################
####################################################################################################
Perplexity Results for Train,Validation, and Test Dataloaders:
[
{
"test_ppl/dataloader_idx_0": 5.116054058074951,
"test_loss/dataloader_idx_0": 1.629224181175232
},
{
"test_ppl/dataloader_idx_1": 5.3178510665893555,
"test_loss/dataloader_idx_1": 1.6678695678710938
},
{
"test_ppl/dataloader_idx_2": 5.311741352081299,
"test_loss/dataloader_idx_2": 1.6666892766952515
}
]
####################################################################################################
####################################################################################################
Training OOVs rate: 1.20
Validation OOVs rate: 1.20
Test OOVs rate: 1.20
####################################################################################################
####################################################################################################
Training Time: 21903.831 seconds
####################################################################################################
####################################################################################################
Average training Time for one epoch: 1991.257 seconds
####################################################################################################
####################################################################################################
<bos>فال رسول الله صلى الله علبه وسلم من ببى اسراىبل على
####################################################################################################
####################################################################################################
Undotted Training Finished for tokenizer FarasaMorphologicalTokenizer at 2023-09-30 01:04:41.834232
####################################################################################################
