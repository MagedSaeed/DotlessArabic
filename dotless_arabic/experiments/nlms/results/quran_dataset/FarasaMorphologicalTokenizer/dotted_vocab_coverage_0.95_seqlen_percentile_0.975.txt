####################################################################################################
Number of samples:
6236
####################################################################################################
####################################################################################################
Dotted Training Started at 2023-04-26 11:51:54.717594 for tokenizer: FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before training:
بسم الله الرحمن الرحيم
الحمد لله رب العالمين
الرحمن الرحيم
مالك يوم الدين
اياك نعبد واياك نستعين
####################################################################################################
####################################################################################################
Train Samples: 5,331
Val Samples: 281
Test Samples: 624
####################################################################################################
####################################################################################################
Calculating vocab size using WordTokenizer:
####################################################################################################
####################################################################################################
Considered Vocab (from WordTokenizer): 10,116
All Vocab (WordTokenizer): 13,439
####################################################################################################
####################################################################################################
Tokenizer Vocab Size: 5,576
####################################################################################################
####################################################################################################
Calculating Sequence Length:
####################################################################################################
####################################################################################################
Sequence Length: 97
####################################################################################################
####################################################################################################
Building DataLoaders
####################################################################################################
####################################################################################################
Train DataLoader: 41
Val DataLoader: 2
Test DataLoader: 4
####################################################################################################
####################################################################################################
| Name               | Type      | Params
-------------------------------------------------
0 | embedding_layer    | Embedding | 2.9 M
1 | gru_layer          | GRU       | 6.3 M
2 | first_dense_layer  | Linear    | 262 K
3 | dropout_layer      | Dropout   | 0
4 | relu               | ReLU      | 0
5 | second_dense_layer | Linear    | 2.9 M
-------------------------------------------------
9.4 M     Trainable params
0         Non-trainable params
9.4 M     Total params
37.708    Total estimated model params size (MB)
####################################################################################################
####################################################################################################
Training Perplexity: 8.29873555438328
Perplexity with OOVs: 14.507369193815679
Perplexity without OOVs: 57.509681600178446
####################################################################################################
####################################################################################################
Training OOVs rate: 36.47
Validation OOVs rate: 36.47
Test OOVs rate: 36.47
####################################################################################################
####################################################################################################
Training Time: 91.76 seconds
####################################################################################################
####################################################################################################
<bos>وما<UNK>كانوا<UNK>لالكافرين
####################################################################################################
####################################################################################################
Dotted Training Finished for tokenizer FarasaMorphologicalTokenizer at 2023-04-26 11:54:15.719714
####################################################################################################
