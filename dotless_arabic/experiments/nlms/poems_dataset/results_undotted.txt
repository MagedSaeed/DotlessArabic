################################################################################
Undotted Training Started
################################################################################
################################################################################
Some of the Dataset Samples after undotting:
اصٮح الملك للدى ڡطر الحل ٯ ٮٮڡدىر للعرىر العلىم
عاڡر الدٮٮ للمسىء ٮعڡو ڡاٮل الٮوٮ دى العطاء العمىم
مرسل المصطڡى الٮسىر الىٮا رحمه مٮه ٮالكلام الڡدىم
رٮٮا رٮٮا الىك اٮىٮا ڡاحرٮا مں حر ٮار الححىم
واكڡٮا سر ما ٮحاڡ ٮلطڡ ىا عطىما ىرحى لكل عطىم
################################################################################
################################################################################
Train Samples: 2,263,705
Val Samples: 22,866
Test Samples: 254,064
################################################################################
################################################################################
Considered Vocab: 61,358
All Vocab: 560,261
################################################################################
################################################################################
Tokenizer Vocab Size (to make sure): 61,358
################################################################################
################################################################################
Sequence Length: 10
################################################################################
################################################################################
Train DataLoader: 8,835
Val DataLoader: 89
Test DataLoader: 991
################################################################################
################################################################################
| Name               | Type      | Params
-------------------------------------------------
0 | embedding_layer    | Embedding | 24.5 M
1 | gru_layer          | GRU       | 2.9 M
2 | first_dense_layer  | Linear    | 160 K
3 | dropout_layer      | Dropout   | 0
4 | relu               | ReLU      | 0
5 | second_dense_layer | Linear    | 24.6 M
-------------------------------------------------
52.2 M    Trainable params
0         Non-trainable params
52.2 M    Total params
208.781   Total estimated model params size (MB)
################################################################################
################################################################################
Training Perplexity: 2041.5568801644934
Perplexity with OOVs: 2417.14344279347
Perplexity without OOVs: 4,473.279010972588
################################################################################
################################################################################
Training Time: 8558.45 seconds
################################################################################
################################################################################
<bos>  ڡى الرٮع مں <eos>
على ما كاں <eos>
مں دا
################################################################################
################################################################################
Undotted Training Finished
################################################################################
