################################################################################
Dotted Training Started
################################################################################
################################################################################
Sample of datasets samples:
أَصبَحَ المُلك لِلَّذي فَطر الخَل قَ بِتَقديرٍ للعَزيز العَليمِ
غافر الذَنب للمسيءِ بِعَفوٍ قابل التَوب ذي العَطاء العَميمِ
مُرسل المُصطَفى البَشير إِلَينا رَحمة مِنهُ بِالكَلام القَديمِ
رَبَنا رَبّنا إِلَيكَ أَنينا فَأَجرنا مِن حَر نار الجَحيمِ
وَاكفِنا شَرّ ما نَخاف بِلُطفٍ يا عَظيماً يَرجى لِكُل عَظيمِ
################################################################################
################################################################################
Number of Baits:
3,845,240
################################################################################
################################################################################
Number of baits after deleting 60>len(bait)>=5 chars:
2,540,635
################################################################################
################################################################################
Some of the Dataset Samples after processing:
اصبح الملك للذي فطر الخل ق بتقدير للعزيز العليم
غافر الذنب للمسيء بعفو قابل التوب ذي العطاء العميم
مرسل المصطفى البشير الينا رحمة منه بالكلام القديم
ربنا ربنا اليك انينا فاجرنا من حر نار الجحيم
واكفنا شر ما نخاف بلطف يا عظيما يرجى لكل عظيم
################################################################################
################################################################################
Train Samples: 2,263,705
Val Samples: 22,866
Test Samples: 254,064
################################################################################
################################################################################
Considered Vocab: 99,816
All Vocab: 776,829
################################################################################
################################################################################
Tokenizer Vocab Size (to make sure): 99,816
################################################################################
################################################################################
Sequence Length: 10
################################################################################
################################################################################
Train DataLoader: 8,835
Val DataLoader: 89
Test DataLoader: 991
################################################################################
################################################################################
| Name               | Type      | Params
-------------------------------------------------
0 | embedding_layer    | Embedding | 39.9 M
1 | gru_layer          | GRU       | 2.9 M
2 | first_dense_layer  | Linear    | 160 K
3 | dropout_layer      | Dropout   | 0
4 | relu               | ReLU      | 0
5 | second_dense_layer | Linear    | 40.0 M
-------------------------------------------------
83.0 M    Trainable params
0         Non-trainable params
83.0 M    Total params
332.001   Total estimated model params size (MB)
################################################################################
################################################################################
Training Perplexity: 2308.009422366665
Perplexity with OOVs: 2855.4732116776277
Perplexity without OOVs: 5,423.79713216548
################################################################################
################################################################################
Training Time: 14492.89 seconds
################################################################################
################################################################################
<bos>  في كل يوم <eos>
و لم يعد <eos>
يا هذا
################################################################################
################################################################################
Dotted Training Finished
################################################################################
