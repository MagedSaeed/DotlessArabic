{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Explorer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to check and validate the functions in the NLMs training pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind, to properly run this noteobook, set the root folder to be the root of this repository at the same level as dotless_arabic.\n",
    "To set this in jupyter vscode:\n",
    "\n",
    "go to setting > search for Notebook File Root > change its value from `${fileDirname}` to `${workspaceFolder}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/majed.alshaibani/.virtualenvs/dotless_arabic/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tkseem as tk\n",
    "from dotless_arabic.processing import process\n",
    "from dotless_arabic.experiments.nlms.src.utils import get_tokenizer\n",
    "from dotless_arabic.experiments.nlms.quran_dataset.collect import collect_dataset as collect_quran_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "Number of samples:\n",
      "6236\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6236"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = collect_quran_dataset()\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FarasaMorphologicalTokenizer...\n"
     ]
    }
   ],
   "source": [
    "tok = get_tokenizer(\n",
    "    vocab_size=10_000,\n",
    "    train_dataset=list(map(process,dataset)),\n",
    "    tokenizer_class=tk.FarasaMorphologicalTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ويعود الفضل في توحيد اللغة العربية الى نزول القران الكريم حيث لم تكن موحدة قبل هذا العهد رغم انها كانت ذات غنى ومرونة الى ان نزل القران الكريم وتحدى الجموع ببيانه واعطى اللغة العربية سيلا من حسن السبك وعذوبة السجع ومن البلاغة والبيان ما عجز عنه بلغاء العرب وقد وحد القران الكريم اللغة العربية توحيدا كاملا وحفظها من التلاشي والانقراض كما حدث مع العديد من اللغات السامية الاخرى التي اضحت لغات باىدة واندثرت مع الزمن او لغات طالها الضعف والانحطاط وبالتالي عدم القدرة على مسايرة التغييرات والتجاذبات التي تعرفها الحضارة وشعوب العالم القديم والحديث'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://ar.wikipedia.org/wiki/%D8%A7%D9%84%D9%82%D8%B1%D8%A2%D9%86\n",
    "sample_text = process(\"\"\"\n",
    "ويعود الفضل في توحيد اللغة العربية إلى نزول القرآن الكريم، حيث لم تكن موحدة قبل هذا العهد رغم أنها كانت ذات غنى ومرونة، إلى أن نزل القرآن الكريم وتحدى الجموع ببيانه، وأعطى اللغة العربية سيلا من حسن السبك وعذوبة السجع ومن البلاغة والبيان ما عجز عنه بلغاء العرب. وقد وحد القرآن الكريم اللغة العربية توحيدا كاملا وحفظها من التلاشي والانقراض، كما حدث مع العديد من اللغات السامية الأخرى، التي أضحت لغات بائدة واندثرت مع الزمن، أو لغات طالها الضعف والانحطاط، وبالتالي عدم القدرة على مسايرة التغييرات والتجاذبات التي تعرفها الحضارة وشعوب العالم القديم والحديث\n",
    "\"\"\")\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 'الف', '##ضل', 'في', -1, -1, 'ال', '##عربي', '##ة', 'الى', -1, 'الق', '##ر', '##ان', 'ال', '##كريم', 'حيث', 'لم', 'تكن', -1, 'قبل', 'هذا', 'ال', '##عهد', -1, 'انها', 'كان', '##ت', 'ذات', -1, 'و', '##مرو', '##ن', '##ة', 'الى', 'ان', 'نزل', 'الق', '##ر', '##ان', 'ال', '##كريم', -1, -1, 'ب', '##بيان', '##ه', -1, -1, 'ال', '##عربي', '##ة', 'سيل', '##ا', 'من', 'حسن', 'ال', '##س', '##بك', -1, -1, 'ومن', 'ال', '##بلاغ', '##ة', 'وال', '##بيان', 'ما', -1, 'عن', '##ه', -1, -1, -1, 'وحد', 'الق', '##ر', '##ان', 'ال', '##كريم', -1, 'ال', '##عربي', '##ة', -1, 'كامل', '##ا', 'و', '##حفظ', '##ها', 'من', -1, -1, 'كما', -1, 'مع', -1, 'من', -1, 'ال', '##س', '##امي', '##ة', -1, 'التي', -1, 'لغ', '##ات', -1, -1, 'مع', 'الزم', '##ن', 'او', 'لغ', '##ات', 'طال', '##ها', 'ال', '##ضعف', -1, 'و', '##ب', '##ال', '##تالي', -1, -1, 'على', 'مس', '##اي', '##ر', '##ة', 'ال', '##ت', '##غي', '##ي', '##ر', '##ات', -1, 'التي', 'تعرف', '##ها', -1, -1, 'ال', '##عالم', -1, 'وال', '##حديث']\n"
     ]
    }
   ],
   "source": [
    "# tokenization using tkseem _base tokenize method\n",
    "print([-1 if item == '<UNK>' else item for item in tok.tokenize(sample_text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['و', -1, 'ال', '##فضل', 'في', -1, 'ال', -1, '##ة', 'ال', '##عربي', '##ة', 'الى', -1, 'ال', '##قران', 'ال', '##كريم', 'حيث', 'لم', 'تكن', -1, '##ة', 'قبل', 'هذا', 'ال', '##عهد', -1, 'ان', '##ها', 'كان', '##ت', 'ذات', -1, 'و', -1, '##ة', 'الى', 'ان', 'نزل', 'ال', '##قران', 'ال', '##كريم', 'و', -1, 'ال', -1, 'ب', '##بيان', '##ه', 'و', '##أعطى', 'ال', -1, '##ة', 'ال', '##عربي', '##ة', 'سيل', '##ا', 'من', 'حسن', 'ال', -1, 'و', -1, '##ة', 'ال', -1, 'و', '##من', 'ال', '##بلاغ', '##ة', 'و', '##ال', '##بيان', 'ما', -1, 'عن', '##ه', -1, 'ال', -1, 'و', '##قد', 'وحد', 'ال', '##قران', 'ال', '##كريم', 'ال', -1, '##ة', 'ال', '##عربي', '##ة', -1, '##ا', 'كامل', '##ا', 'و', '##حفظ', '##ها', 'من', 'ال', -1, 'و', '##ال', -1, 'كما', -1, 'مع', 'ال', -1, 'من', 'ال', -1, '##ات', 'ال', -1, '##ة', 'ال', '##أخرى', 'التي', -1, '##ت', 'لغ', '##ات', 'ب', -1, '##ة', 'و', -1, '##ت', 'مع', 'ال', -1, 'أو', 'لغ', '##ات', 'طال', '##ها', 'ال', '##ضعف', 'و', '##ال', -1, 'و', '##ب', '##ال', '##تالي', -1, 'ال', '##قدر', '##ة', 'على', -1, '##ة', 'ال', -1, '##ات', 'و', '##ال', -1, '##ات', 'التي', 'تعرف', '##ها', 'ال', -1, '##ة', 'و', -1, 'ال', '##عالم', 'ال', '##قديم', 'و', '##ال', '##حديث']\n"
     ]
    }
   ],
   "source": [
    "# tokenization using tkseem farasa_morphological_tokenizer tokenize method\n",
    "print([-1 if item == '<UNK>' else item for item in tok.tokenize(sample_text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farasa.segmenter import FarasaSegmenter\n",
    "seg = FarasaSegmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['و', '##يعود', 'ال', '##فضل', 'في', 'توحيد', 'ال', '##لغ', '##ة', 'ال', '##عربي', '##ة', 'الى', 'نزول', 'ال', '##قران', 'ال', '##كريم', 'حيث', 'لم', 'تكن', 'موحد', '##ة', 'قبل', 'هذا', 'ال', '##عهد', 'رغم', 'ان', '##ها', 'كان', '##ت', 'ذات', 'غنى', 'و', '##مرون', '##ة', 'الى', 'ان', 'نزل', 'ال', '##قران', 'ال', '##كريم', 'و', '##تحدى', 'ال', '##جموع', 'ب', '##بيان', '##ه', 'و', '##أعطى', 'ال', '##لغ', '##ة', 'ال', '##عربي', '##ة', 'سيل', '##ا', 'من', 'حسن', 'ال', '##سبك', 'و', '##عذوب', '##ة', 'ال', '##سجع', 'و', '##من', 'ال', '##بلاغ', '##ة', 'و', '##ال', '##بيان', 'ما', 'عجز', 'عن', '##ه', 'بلغاء', 'ال', '##عرب', 'و', '##قد', 'وحد', 'ال', '##قران', 'ال', '##كريم', 'ال', '##لغ', '##ة', 'ال', '##عربي', '##ة', 'توحيد', '##ا', 'كامل', '##ا', 'و', '##حفظ', '##ها', 'من', 'ال', '##تلاشي', 'و', '##ال', '##انقراض', 'كما', 'حدث', 'مع', 'ال', '##عديد', 'من', 'ال', '##لغ', '##ات', 'ال', '##سامي', '##ة', 'ال', '##أخرى', 'التي', 'اضح', '##ت', 'لغ', '##ات', 'ب', '##اىد', '##ة', 'و', '##اندثر', '##ت', 'مع', 'ال', '##زمن', 'أو', 'لغ', '##ات', 'طال', '##ها', 'ال', '##ضعف', 'و', '##ال', '##انحطاط', 'و', '##ب', '##ال', '##تالي', 'عدم', 'ال', '##قدر', '##ة', 'على', 'مساير', '##ة', 'ال', '##تغيير', '##ات', 'و', '##ال', '##تجاذب', '##ات', 'التي', 'تعرف', '##ها', 'ال', '##حضار', '##ة', 'و', '##شعوب', 'ال', '##عالم', 'ال', '##قديم', 'و', '##ال', '##حديث']\n"
     ]
    }
   ],
   "source": [
    "print(seg.segment(sample_text).replace('+',' ##').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dotless_arabic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "516da04de80167238ea48024668c24cf7cf75725fea03e4c551f9aafb099be3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
