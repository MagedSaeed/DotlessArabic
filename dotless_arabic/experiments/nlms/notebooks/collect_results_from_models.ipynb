{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/home/g201381710/ExperimentsGH/DotlessArabic/')\n",
    "# sys.path.append('/home/g201381710/.local/lib/python3.10/site-packages')\n",
    "\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/majed_alshaibani/Experiments/DotlessArabic\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tkseem as tk\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dotless_arabic.processing import process,undot\n",
    "from dotless_arabic.experiments.nlms.src import constants\n",
    "from dotless_arabic.experiments.nlms.src.models import LitNeuralLanguageModel\n",
    "from dotless_arabic.experiments.constants import COLLECT_DATASET_FOR_LANGUAGE_MODELLING\n",
    "from dotless_arabic.tokenizers import WordTokenizer,FarasaMorphologicalTokenizer,DisjointLetterTokenizer,CharacterTokenizer\n",
    "from dotless_arabic.experiments.nlms.src.utils import generate_text,get_best_checkpoint,get_tokenizer,get_dataloader,calculate_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the dataset name here :)\n",
    "dataset_name = 'wikipedia'\n",
    "dataset_type = 'undotted'\n",
    "tokenizer_class = FarasaMorphologicalTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Sample of datasets samples:\n",
      "الماء مادةٌ شفافةٌ عديمة اللون والرائحة، وهو المكوّن الأساسي للجداول والبحيرات والبحار والمحيطات وكذلك للسوائل في جميع الكائنات الحيّة، وهو أكثر المركّبات الكيميائيّة انتشاراً على سطح الأرض. يتألّف جزيء الماء من ذرّة أكسجين مركزية ترتبط بها ذرّتا هيدروجين على طرفيها برابطة تساهميّة بحيث تكون صيغته الكيميائية H2O. عند الظروف القياسية من الضغط ودرجة الحرارة يكون الماء سائلاً؛ أمّا الحالة الصلبة فتتشكّل عند نقطة التجمّد، وتدعى بالجليد؛ أمّا الحالة الغازية فتتشكّل عند نقطة الغليان، وتسمّى بخار الماء.\n",
      "إنّ الماء هو أساس وجود الحياة على كوكب الأرض، وهو يغطّي 71% من سطحها، وتمثّل مياه البحار والمحيطات أكبر نسبة للماء على الأرض، حيث تبلغ حوالي 96.5%. وتتوزّع النسب الباقية بين المياه الجوفيّة وبين جليد المناطق القطبيّة (1.7% لكليهما)، مع وجود نسبة صغيرة على شكل بخار ماء معلّق في الهواء على هيئة سحاب (غيوم)، وأحياناً أخرى على هيئة ضباب أو ندى، بالإضافة إلى الزخات المطريّة أو الثلجيّة. تبلغ نسبة الماء العذب حوالي 2.5% فقط من الماء الموجود على الأرض، وأغلب هذه الكمّيّة (حوالي 99%) موجودة في الكتل الجليديّة في المناطق القطبيّة، في حين تتواجد 0.3% من الماء العذب في الأنهار والبحيرات وفي الغلاف الجوّي.\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Number of Samples before transformations:\n",
      "5,609,905\n",
      "####################################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84a7e675dc8450cb0169f2ccec4bdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5609905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c316df29f7e4ed287fd1932799cadb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5578668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Number of Samples after transformations:\n",
      "11,872,890\n",
      "####################################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08f4e5b07254dd7a130ef0257d3f353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11872890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Number of Samples when considering sample with 30 tokens or more:\n",
      "1,469,112\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "dataset = COLLECT_DATASET_FOR_LANGUAGE_MODELLING[dataset_name]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec28ae1b24734c408c4f9db1eaf927d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1469112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = list(\n",
    "    map(\n",
    "        process,\n",
    "        tqdm(dataset),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f25e860d5f84b77be8d558ed3bf0b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1469112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if dataset_type=='undotted':\n",
    "    dataset = list(\n",
    "        map(\n",
    "            undot,\n",
    "            tqdm(dataset),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(\n",
    "        dataset,\n",
    "        shuffle=True,\n",
    "        test_size=constants.TEST_SIZE,\n",
    "        random_state=constants.RANDOM_SEED,\n",
    "    )\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    test_size=constants.VAL_SIZE,\n",
    "    random_state=constants.RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitNeuralLanguageModel(\n",
       "  (embedding_layer): Embedding(8218, 512)\n",
       "  (gru_layer): GRU(512, 512, num_layers=4, batch_first=True)\n",
       "  (first_dense_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (dropout_layer): Dropout(p=0.333, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (second_dense_layer): Linear(in_features=512, out_features=8218, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LitNeuralLanguageModel.load_from_checkpoint(\n",
    "        get_best_checkpoint(\n",
    "            tokenizer_class=tokenizer_class,\n",
    "            dataset_id=f\"{dataset_type.upper()}-{dataset_name.upper()}_DATASET\",\n",
    "            checkpoints_base_path=\"/home/majed_alshaibani/Experiments/DotlessArabic/NLMs\",\n",
    "        )\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-22 13:48:57,900 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FarasaMorphologicalTokenizer...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dotless_arabic.tokenizers.FarasaMorphologicalTokenizer at 0x7f131dfbf760>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(\n",
    "        train_dataset=train_dataset,\n",
    "        vocab_size=model.vocab_size,\n",
    "        tokenizer_class=tokenizer_class,\n",
    "    )\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length=269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a040cececdaf4ef380da5086ccc7be3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/146912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606624a8e5c944c3875b8aa1b92e892d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1147 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity_with_oovs: 9.593713079914767\n"
     ]
    }
   ],
   "source": [
    "perplexity_with_oovs = calculate_perplexity(\n",
    "    lm_model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=test_dataset,\n",
    "    batch_size=128,\n",
    "    sequence_length=sequence_length,\n",
    ")\n",
    "print(f'perplexity_with_oovs: {perplexity_with_oovs:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce28a1ca2494bf2885a68753693f81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/146912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0830aba078b04e3091166dd75bd27ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1147 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity_without_oovs: 9.744606261496351\n"
     ]
    }
   ],
   "source": [
    "perplexity_without_oovs = calculate_perplexity(\n",
    "    lm_model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=test_dataset,\n",
    "    batch_size=128,\n",
    "    sequence_length=sequence_length,\n",
    "    ignore_oovs=True,\n",
    ")\n",
    "print(f'perplexity_without_oovs: {perplexity_without_oovs:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b719647ebb9468f943ee9c164298477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1256090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c51019bed249a8a8e8f6af336e1213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9809 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_perplexity: 8.98469655311713\n"
     ]
    }
   ],
   "source": [
    "training_perplexity = calculate_perplexity(\n",
    "    lm_model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=train_dataset,\n",
    "    sequence_length=sequence_length,\n",
    "    batch_size=128,\n",
    ")\n",
    "print(f'training_perplexity: {training_perplexity:,}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
