####################################################################################################
Original Number of Samples:
650,986
####################################################################################################
####################################################################################################
Number of Samples after dropping duplicates:
637,565
####################################################################################################
####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Tokenize the Dataset with DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:
يتو ضا ثلا ثا ير فعه ا لى ا لنبي صلى ا لله عليه و سلم
يغتسل من ا لجنا بة ثم يجيء و له قفقفة فيستد فى بي و لم ا غتسل
لا تبل قا ىما فما بلت بعد قا ىما
ا نت نهيت ا لنا س ا ن يصلو ا في نعا لهم فقا ل لا لعمر ا لله ما نهيت ا لنا س ا ن يصلو ا في نعا لهم غير ا ني و ر ب هذ ه ا لحر مة حتى قا لها ثلا ثا لقد ر ا يت ا لنبي صلى ا لله عليه و سلم ههنا عند ا لمقا م يصلي و عليه نعلا ه ثم ا نصر ف و هما عليه
ا ن ا نا صد قت فصد قني و ا ن ا نا كذ بت فكذ بني قا ل فا فعل قا ل فا نشد ك با لله هل سمعت ر سو ل ا لله صلى ا لله عليه و سلم ينهى عن لبس ا لذ هب قا ل نعم قا ل فا نشد ك با لله هل تعلم ا ن ر سو ل ا لله صلى ا لله عليه و سلم نهى عن لبس ا لحر ير قا ل نعم قا ل فا نشد ك با لله هل تعلم ا ن ر سو ل ا لله صلى ا لله عليه و سلم نهى عن لبس جلو د ا لسبا ع و ا لر كو ب عليها قا ل نعم
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-27 01:32:04.092857 for dataset sanadset_hadeeth_dataset tokenized by DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Samples Count: 637,565
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 76,495
####################################################################################################
####################################################################################################
All Tokens Count: 55,892,178
####################################################################################################
####################################################################################################
vocab/tokens: 0.0014
####################################################################################################
####################################################################################################
Tokens Entropy: 7.6439
####################################################################################################
####################################################################################################
Average tokens length: 4.9529
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.0146
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset sanadset_hadeeth_dataset tokenized by DisjointLetterTokenizer at 2023-03-27 01:32:12.747270
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-27 01:32:12.747310 for dataset sanadset_hadeeth_dataset tokenized by DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Create an undotted tokens frequency mapping and save it to a json file
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
ٮٮو صا ٮلا ٮا ٮر ڡعه ا لى ا لٮٮى صلى ا لله علٮه و سلم
ٮعٮسل مں ا لحٮا ٮه ٮم ٮحٮء و له ڡڡڡڡه ڡٮسٮد ڡى ٮى و لم ا عٮسل
لا ٮٮل ڡا ىما ڡما ٮلٮ ٮعد ڡا ىما
ا ٮٮ ٮهٮٮ ا لٮا س ا ں ٮصلو ا ڡى ٮعا لهم ڡڡا ل لا لعمر ا لله ما ٮهٮٮ ا لٮا س ا ں ٮصلو ا ڡى ٮعا لهم عٮر ا ٮى و ر ٮ هد ه ا لحر مه حٮى ڡا لها ٮلا ٮا لڡد ر ا ٮٮ ا لٮٮى صلى ا لله علٮه و سلم ههٮا عٮد ا لمڡا م ٮصلى و علٮه ٮعلا ه ٮم ا ٮصر ڡ و هما علٮه
ا ں ا ٮا صد ڡٮ ڡصد ڡٮى و ا ں ا ٮا كد ٮٮ ڡكد ٮٮى ڡا ل ڡا ڡعل ڡا ل ڡا ٮسد ك ٮا لله هل سمعٮ ر سو ل ا لله صلى ا لله علٮه و سلم ٮٮهى عں لٮس ا لد هٮ ڡا ل ٮعم ڡا ل ڡا ٮسد ك ٮا لله هل ٮعلم ا ں ر سو ل ا لله صلى ا لله علٮه و سلم ٮهى عں لٮس ا لحر ٮر ڡا ل ٮعم ڡا ل ڡا ٮسد ك ٮا لله هل ٮعلم ا ں ر سو ل ا لله صلى ا لله علٮه و سلم ٮهى عں لٮس حلو د ا لسٮا ع و ا لر كو ٮ علٮها ڡا ل ٮعم
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 37,412
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 55,892,178
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0007
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 7.0981
####################################################################################################
####################################################################################################
Average tokens length: 5.3124
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.1430
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 39,083
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset sanadset_hadeeth_dataset tokenized by DisjointLetterTokenizer at 2023-03-27 01:35:47.266135
####################################################################################################
