####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Tokenize the Dataset with DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:
ا صبح ا لملك للذ ي فطر ا لخل
ق بتقد ير للعز يز ا لعليم
غا فر ا لذ نب للمسيء بعفو
قا بل ا لتو ب ذ ي ا لعطا ء ا لعميم
مر سل ا لمصطفى ا لبشير ا لينا
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-06 03:09:43.489659 for dataset poems_dataset tokenized by DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Samples Count: 7,714,858
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 191,393
####################################################################################################
####################################################################################################
All Tokens Count: 72,450,612
####################################################################################################
####################################################################################################
vocab/tokens: 0.0026
####################################################################################################
####################################################################################################
Tokens Entropy: 8.4800
####################################################################################################
####################################################################################################
Average tokens length: 5.1566
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.2196
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset poems_dataset tokenized by DisjointLetterTokenizer at 2023-03-06 03:09:55.829562
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-06 03:09:55.829598 for dataset poems_dataset tokenized by DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Create an undotted tokens frequency mapping and save it to a json file
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
ا صٮح ا لملك للد ى ڡطر ا لحل
ٯ ٮٮڡد ىر للعر ىر ا لعلىم
عا ڡر ا لد ٮٮ للمسىء ٮعڡو
ڡا ٮل ا لٮو ٮ د ى ا لعطا ء ا لعمىم
مر سل ا لمصطڡى ا لٮسىر ا لىٮا
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 104,220
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 72,450,612
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0014
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 7.8408
####################################################################################################
####################################################################################################
Average tokens length: 5.5169
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.4040
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 87,173
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset poems_dataset tokenized by DisjointLetterTokenizer at 2023-03-06 03:14:23.536979
####################################################################################################
