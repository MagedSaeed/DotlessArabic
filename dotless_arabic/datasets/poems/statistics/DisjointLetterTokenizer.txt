####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Tokenize the Dataset with DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:
ا صبح ا لملك للذ ي فطر ا لخل
ق بتقد ير للعز يز ا لعليم
غا فر ا لذ نب للمسيء بعفو
قا بل ا لتو ب ذ ي ا لعطا ء ا لعميم
مر سل ا لمصطفى ا لبشير ا لينا
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-27 01:39:17.727421 for dataset poems_dataset tokenized by DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Samples Count: 7,714,858
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 191,393
####################################################################################################
####################################################################################################
All Tokens Count: 72,450,612
####################################################################################################
####################################################################################################
vocab/tokens: 0.0026
####################################################################################################
####################################################################################################
Tokens Entropy: 8.4800
####################################################################################################
####################################################################################################
Average tokens length: 5.1566
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.2196
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset poems_dataset tokenized by DisjointLetterTokenizer at 2023-03-27 01:39:31.256380
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-27 01:39:31.256415 for dataset poems_dataset tokenized by DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Create an undotted tokens frequency mapping and save it to a json file
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
ا صٮح ا لملك للد ى ڡطر ا لحل
ٯ ٮٮڡد ٮر للعر ٮر ا لعلٮم
عا ڡر ا لد ٮٮ للمسٮء ٮعڡو
ڡا ٮل ا لٮو ٮ د ى ا لعطا ء ا لعمٮم
مر سل ا لمصطڡى ا لٮسٮر ا لٮٮا
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 79,968
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 72,450,612
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0011
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 7.6867
####################################################################################################
####################################################################################################
Average tokens length: 5.5559
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.3853
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 111,425
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset poems_dataset tokenized by DisjointLetterTokenizer at 2023-03-27 01:44:22.059064
####################################################################################################
