####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Tokenize the Dataset with FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:
أصبح ال ملك ل الذي فطر ال خل
ق ب تقدير ل ال عزيز ال عليم
غافر ال ذنب ل ال مسيء ب عفو
قابل ال توب ذي ال عطاء ال عميم
مرسل ال مصطفى ال بشير إلي نا
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-06 03:54:49.653950 for dataset poems_dataset tokenized by FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Samples Count: 7,714,858
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 361,739
####################################################################################################
####################################################################################################
All Tokens Count: 57,350,212
####################################################################################################
####################################################################################################
vocab/tokens: 0.0063
####################################################################################################
####################################################################################################
Tokens Entropy: 9.6594
####################################################################################################
####################################################################################################
Average tokens length: 5.7911
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.5510
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset poems_dataset tokenized by FarasaMorphologicalTokenizer at 2023-03-06 03:55:01.108348
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-06 03:55:01.108387 for dataset poems_dataset tokenized by FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Create an undotted tokens frequency mapping and save it to a json file
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
اصٮح ال ملك ل الدى ڡطر ال حل
ٯ ٮ ٮڡدىر ل ال عرىر ال علىم
عاڡر ال دٮٮ ل ال مسىء ٮ عڡو
ڡاٮل ال ٮوٮ دى ال عطاء ال عمىم
مرسل ال مصطڡى ال ٮسىر الى ٮا
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 270,370
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 57,350,212
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0047
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 9.2540
####################################################################################################
####################################################################################################
Average tokens length: 6.1392
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.7625
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 91,369
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset poems_dataset tokenized by FarasaMorphologicalTokenizer at 2023-03-06 03:58:34.585655
####################################################################################################
