####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Tokenize the Dataset with DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:
ا لما ء ما د ة شفا فة عد يمة ا للو ن و ا لر ا ىحة و هو ا لمكو ن ا لا سا سي للجد ا و ل و ا لبحير ا ت و ا لبحا ر و ا لمحيطا ت و كذ لك للسو ا ىل في جميع ا لكا ىنا ت ا لحية و هو ا كثر ا لمر كبا ت ا لكيميا ىية ا نتشا ر ا على سطح ا لا ر ض يتا لف جز يء ا لما ء من ذ ر ة ا كسجين مر كز ية تر تبط بها ذ ر تا هيد ر و جين على طر فيها بر ا بطة تسا همية بحيث تكو ن صيغته ا لكيميا ىية عند ا لظر و ف ا لقيا سية من ا لضغط و د ر جة ا لحر ا ر ة يكو ن ا لما ء سا ىلا ا ما ا لحا لة ا لصلبة فتتشكل عند نقطة ا لتجمد و تد عى با لجليد ا ما ا لحا لة ا لغا ز ية فتتشكل عند نقطة ا لغليا ن و تسمى بخا ر ا لما ء
ا ن ا لما ء هو ا سا س و جو د ا لحيا ة على كو كب ا لا ر ض و هو يغطي من سطحها و تمثل ميا ه ا لبحا ر و ا لمحيطا ت ا كبر نسبة للما ء على ا لا ر ض حيث تبلغ حو ا لي و تتو ز ع ا لنسب ا لبا قية بين ا لميا ه ا لجو فية و بين جليد ا لمنا طق ا لقطبية لكليهما مع و جو د نسبة صغير ة على شكل بخا ر ما ء معلق في ا لهو ا ء على هيىة سحا ب غيو م و ا حيا نا ا خر ى على هيىة ضبا ب ا و ند ى با لا ضا فة ا لى ا لز خا ت ا لمطر ية ا و ا لثلجية تبلغ نسبة ا لما ء ا لعذ ب حو ا لي فقط من ا لما ء ا لمو جو د على ا لا ر ض و ا غلب هذ ه ا لكمية حو ا لي مو جو د ة في ا لكتل ا لجليد ية في ا لمنا طق ا لقطبية في حين تتو ا جد من ا لما ء ا لعذ ب في ا لا نها ر و ا لبحير ا ت و في ا لغلا ف ا لجو ي
ا ما في ا لطبيعة فتتغير حا لة ا لما ء بين ا لحا لا ت ا لثلا ثة للما د ة على سطح ا لا ر ض با ستمر ا ر من خلا ل ما يعر ف با سم ا لد و ر ة ا لما ىية ا و د و ر ة ا لما ء و ا لتي تتضمن حد و ث تبخر و نتح نتح تبخر ي ثم تكثيف فهطو ل ثم جر يا ن لتصل ا لى ا لمصب في ا لمسطحا ت ا لما ىية
شكل ا لحصو ل على مصد ر نقي من ميا ه ا لشر ب ا مر ا مهما لنشو ء ا لحضا ر ا ت عبر ا لتا ر يخ و في ا لعقو د ا لا خير ة سجلت حا لا ت شح في ا لميا ه ا لعذ بة في منا طق عد يد ة من ا لعا لم و لقد قد ر ت ا حصا ء ا ت ا لا مم ا لمتحد ة ا ن حو ا لي مليا ر شخص على سطح ا لا ر ض لا يز ا لو ن يفتقر و ن ا لو سا ىل ا لمتا حة للو صو ل ا لى مصد ر ا من لميا ه ا لشر ب و ا ن حو ا لي مليا ر يفتقر و ن ا لى و سيلة ملا ىمة من ا جل تطهير ا لميا ه
ا لخو ا ص ا لفيز يا ىية و ا لكيميا ىية
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-27 01:55:37.623832 for dataset wikipedia_dataset tokenized by DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Samples Count: 4,636,663
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 266,822
####################################################################################################
####################################################################################################
All Tokens Count: 412,843,347
####################################################################################################
####################################################################################################
vocab/tokens: 0.0006
####################################################################################################
####################################################################################################
Tokens Entropy: 8.1534
####################################################################################################
####################################################################################################
Average tokens length: 5.5446
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.6101
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset wikipedia_dataset tokenized by DisjointLetterTokenizer at 2023-03-27 01:56:43.699733
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-27 01:56:43.699768 for dataset wikipedia_dataset tokenized by DisjointLetterTokenizer
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Create an undotted tokens frequency mapping and save it to a json file
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
ا لما ء ما د ه سڡا ڡه عد ٮمه ا للو ں و ا لر ا ىحه و هو ا لمكو ں ا لا سا سى للحد ا و ل و ا لٮحٮر ا ٮ و ا لٮحا ر و ا لمحٮطا ٮ و كد لك للسو ا ىل ڡى حمٮع ا لكا ىٮا ٮ ا لحٮه و هو ا كٮر ا لمر كٮا ٮ ا لكٮمٮا ىٮه ا ٮٮسا ر ا على سطح ا لا ر ص ٮٮا لڡ حر ٮء ا لما ء مں د ر ه ا كسحٮں مر كر ٮه ٮر ٮٮط ٮها د ر ٮا هٮد ر و حٮں على طر ڡٮها ٮر ا ٮطه ٮسا همٮه ٮحٮٮ ٮكو ں صٮعٮه ا لكٮمٮا ىٮه عٮد ا لطر و ڡ ا لڡٮا سٮه مں ا لصعط و د ر حه ا لحر ا ر ه ٮكو ں ا لما ء سا ىلا ا ما ا لحا له ا لصلٮه ڡٮٮسكل عٮد ٮڡطه ا لٮحمد و ٮد عى ٮا لحلٮد ا ما ا لحا له ا لعا ر ٮه ڡٮٮسكل عٮد ٮڡطه ا لعلٮا ں و ٮسمى ٮحا ر ا لما ء
ا ں ا لما ء هو ا سا س و حو د ا لحٮا ه على كو كٮ ا لا ر ص و هو ٮعطى مں سطحها و ٮمٮل مٮا ه ا لٮحا ر و ا لمحٮطا ٮ ا كٮر ٮسٮه للما ء على ا لا ر ص حٮٮ ٮٮلع حو ا لى و ٮٮو ر ع ا لٮسٮ ا لٮا ڡٮه ٮٮں ا لمٮا ه ا لحو ڡٮه و ٮٮں حلٮد ا لمٮا طٯ ا لڡطٮٮه لكلٮهما مع و حو د ٮسٮه صعٮر ه على سكل ٮحا ر ما ء معلٯ ڡى ا لهو ا ء على هٮىه سحا ٮ عٮو م و ا حٮا ٮا ا حر ى على هٮىه صٮا ٮ ا و ٮد ى ٮا لا صا ڡه ا لى ا لر حا ٮ ا لمطر ٮه ا و ا لٮلحٮه ٮٮلع ٮسٮه ا لما ء ا لعد ٮ حو ا لى ڡڡط مں ا لما ء ا لمو حو د على ا لا ر ص و ا علٮ هد ه ا لكمٮه حو ا لى مو حو د ه ڡى ا لكٮل ا لحلٮد ٮه ڡى ا لمٮا طٯ ا لڡطٮٮه ڡى حٮں ٮٮو ا حد مں ا لما ء ا لعد ٮ ڡى ا لا ٮها ر و ا لٮحٮر ا ٮ و ڡى ا لعلا ڡ ا لحو ى
ا ما ڡى ا لطٮٮعه ڡٮٮعٮر حا له ا لما ء ٮٮں ا لحا لا ٮ ا لٮلا ٮه للما د ه على سطح ا لا ر ص ٮا سٮمر ا ر مں حلا ل ما ٮعر ڡ ٮا سم ا لد و ر ه ا لما ىٮه ا و د و ر ه ا لما ء و ا لٮى ٮٮصمں حد و ٮ ٮٮحر و ٮٮح ٮٮح ٮٮحر ى ٮم ٮكٮٮڡ ڡهطو ل ٮم حر ٮا ں لٮصل ا لى ا لمصٮ ڡى ا لمسطحا ٮ ا لما ىٮه
سكل ا لحصو ل على مصد ر ٮڡى مں مٮا ه ا لسر ٮ ا مر ا مهما لٮسو ء ا لحصا ر ا ٮ عٮر ا لٮا ر ٮح و ڡى ا لعڡو د ا لا حٮر ه سحلٮ حا لا ٮ سح ڡى ا لمٮا ه ا لعد ٮه ڡى مٮا طٯ عد ٮد ه مں ا لعا لم و لڡد ڡد ر ٮ ا حصا ء ا ٮ ا لا مم ا لمٮحد ه ا ں حو ا لى ملٮا ر سحص على سطح ا لا ر ص لا ٮر ا لو ں ٮڡٮڡر و ں ا لو سا ىل ا لمٮا حه للو صو ل ا لى مصد ر ا مں لمٮا ه ا لسر ٮ و ا ں حو ا لى ملٮا ر ٮڡٮڡر و ں ا لى و سٮله ملا ىمه مں ا حل ٮطهٮر ا لمٮا ه
ا لحو ا ص ا لڡٮر ٮا ىٮه و ا لكٮمٮا ىٮه
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 118,150
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 412,843,347
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0003
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 7.4934
####################################################################################################
####################################################################################################
Average tokens length: 6.0712
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 4.8674
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 148,672
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset wikipedia_dataset tokenized by DisjointLetterTokenizer at 2023-03-27 02:23:41.093079
####################################################################################################
