####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Tokenize the Dataset with FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:

ال تريمس ة قري ة تتبع منطق ة محرد ة في محافظ ة حما ة في سوري ة في سن ة بلغ عدد سكان ها نسم ة

ال قبل ة محل ة تابع ة ل قري ة ال عله ة ال تابع ة ل عزل ة دلال ب مديري ة بعد ان إحدى مديري ات محافظ ة اب في ال جمهوري ة ال يمني ة بلغ تعداد سكان ها حسب تعداد ال يمن ل عام
ف ذاك خلق من ال فردوس طين ت ه الله أودع في ها ما ينقي ها
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-06 06:04:53.023734 for dataset wikipedia_dataset tokenized by FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Samples Count: 4,636,663
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 1,002,148
####################################################################################################
####################################################################################################
All Tokens Count: 303,831,223
####################################################################################################
####################################################################################################
vocab/tokens: 0.0033
####################################################################################################
####################################################################################################
Tokens Entropy: 8.8921
####################################################################################################
####################################################################################################
Average tokens length: 7.3234
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 5.9748
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset wikipedia_dataset tokenized by FarasaMorphologicalTokenizer at 2023-03-06 06:05:45.295032
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-06 06:05:45.295069 for dataset wikipedia_dataset tokenized by FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Create an undotted tokens frequency mapping and save it to a json file
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:

ال ٮرىمس ه ڡرى ه ٮٮٮع مٮطٯ ه محرد ه ڡى محاڡط ه حما ه ڡى سورى ه ڡى سں ه ٮلع عدد سكاں ها ٮسم ه

ال ڡٮل ه محل ه ٮاٮع ه ل ڡرى ه ال عله ه ال ٮاٮع ه ل عرل ه دلال ٮ مدىرى ه ٮعد اں احدى مدىرى اٮ محاڡط ه اٮ ڡى ال حمهورى ه ال ىمٮى ه ٮلع ٮعداد سكاں ها حسٮ ٮعداد ال ىمں ل عام
ڡ داك حلٯ مں ال ڡردوس طىں ٮ ه الله اودع ڡى ها ما ىٮڡى ها
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 851,616
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 303,831,223
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0028
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 8.6590
####################################################################################################
####################################################################################################
Average tokens length: 7.6832
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 6.2894
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 150,532
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset wikipedia_dataset tokenized by FarasaMorphologicalTokenizer at 2023-03-06 06:23:40.924280
####################################################################################################
