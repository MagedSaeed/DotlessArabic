####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Tokenize the Dataset with WordTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:

وشددوا على البقاء حازمين لجهة دعم الشعب الاوكراني الذي يسعى الى استعادة وحدته وديموقراطيته واستقراره السياسي وازدهاره الاقتصادي
وحيا معاليه الصورة الحضارية التي خرج بها الاحتفال داعيا الطالبات الى مواصلة النجاح بتفوق وعدم الاكتفاء بالوصول الى منصات التتويج
وجاء في احدى الوثاىق السرية ان تاتشر اضطرت عام لاستعارة مجموعة لتصفيف الشعر من موظفة في السفارة البريطانية في بيجينج خلال زيارة قامت بها الى الصين وطلبت عام من السفير البريطاني لدى طهران انطوني بارسونز ترتيب موعد لها مع مصففة شعر محلية جيدة قبل قيامها بزيارة الى ايران
كما تعزز من امكانياته خدمة المستفيدين والبرامج التي تخدم مجتمع الامارات وقضايا الهوية الوطنية وذلك انطلاقا من توجيهات صاحب السمو الشيخ خليفة بن زايد ال نهيان رىيس الدولة حفظه الله في ان يكون عام عاما للهوية الوطنية وذلك من خلال عقد الندوات وبرامج التدريب وورش العمل التي تخدم اهداف المركز الى جانب تشجيع الدراسات والبحوث المبتكرة وتسجيل التراث الوثاىقي والمواد الارشيفية الكترونيا
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-06 03:31:07.126225 for dataset news_dataset tokenized by WordTokenizer
####################################################################################################
####################################################################################################
Samples Count: 2,784,041
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 892,583
####################################################################################################
####################################################################################################
All Tokens Count: 134,862,816
####################################################################################################
####################################################################################################
vocab/tokens: 0.0066
####################################################################################################
####################################################################################################
Tokens Entropy: 13.1012
####################################################################################################
####################################################################################################
Average tokens length: 6.7267
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 6.1262
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset news_dataset tokenized by WordTokenizer at 2023-03-06 03:31:37.301395
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-06 03:31:37.301433 for dataset news_dataset tokenized by WordTokenizer
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Create an undotted tokens frequency mapping and save it to a json file
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:

وسددوا على الٮڡاء حارمىں لحهه دعم السعٮ الاوكراٮى الدى ىسعى الى اسٮعاده وحدٮه ودىموڡراطىٮه واسٮڡراره السىاسى واردهاره الاڡٮصادى
وحىا معالىه الصوره الحصارىه الٮى حرح ٮها الاحٮڡال داعىا الطالٮاٮ الى مواصله الٮحاح ٮٮڡوٯ وعدم الاكٮڡاء ٮالوصول الى مٮصاٮ الٮٮوىح
وحاء ڡى احدى الوٮاىٯ السرىه اں ٮاٮسر اصطرٮ عام لاسٮعاره محموعه لٮصڡىڡ السعر مں موطڡه ڡى السڡاره الٮرىطاٮىه ڡى ٮىحىٮح حلال رىاره ڡامٮ ٮها الى الصىں وطلٮٮ عام مں السڡىر الٮرىطاٮى لدى طهراں اٮطوٮى ٮارسوٮر ٮرٮىٮ موعد لها مع مصڡڡه سعر محلىه حىده ڡٮل ڡىامها ٮرىاره الى اىراں
كما ٮعرر مں امكاٮىاٮه حدمه المسٮڡىدىں والٮرامح الٮى ٮحدم محٮمع الاماراٮ وڡصاىا الهوىه الوطٮىه ودلك اٮطلاڡا مں ٮوحىهاٮ صاحٮ السمو السىح حلىڡه ٮں راىد ال ٮهىاں رىىس الدوله حڡطه الله ڡى اں ىكوں عام عاما للهوىه الوطٮىه ودلك مں حلال عڡد الٮدواٮ وٮرامح الٮدرىٮ وورس العمل الٮى ٮحدم اهداڡ المركر الى حاٮٮ ٮسحىع الدراساٮ والٮحوٮ المٮٮكره وٮسحىل الٮراٮ الوٮاىڡى والمواد الارسىڡىه الكٮروٮىا
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 728,986
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 134,862,816
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0054
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 12.9655
####################################################################################################
####################################################################################################
Average tokens length: 6.9887
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 6.2204
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 163,597
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset news_dataset tokenized by WordTokenizer at 2023-03-06 03:40:01.220670
####################################################################################################
