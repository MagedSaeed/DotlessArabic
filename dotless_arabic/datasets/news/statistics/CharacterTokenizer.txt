####################################################################################################
Tokenize the Dataset with CharacterTokenizer
####################################################################################################
####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:

و م ع د خ و ل ا ل م ب ا ر ا ة ف ي ش و ط ه ا ا ل ث ا ن ي ا ن ت ف ض ا ل و ص ل م ن ك ب و ت ه م ن خ ل ا ل ا ع ت م ا د م د ر ب ه ا ل م ق د و ن ي ي و ر د ا ن ك و د ي ف ي د ب ا ك و ف ع ل ى ا س ل و ب ا ل د ف ا ع ا ل ض ا غ ط ا ل ذ ي ا ت ا ح م ك ن ل ا ع ب ي ه م ن ا ي ق ا ف خ ط و ر ة ا ل ش ب ا ب م ن ه ي ا ا ل ر ب ع ا ل ث ا ل ث ل م ص ل ح ت ه ب ف ا ر ق س ت ن ق ا ط و ب ن ت ي ج ة ب ن ي ل ا ل ف ر ي ق ا ل ا ص ف ر ا ل ا ف ض ل ي ة ب ن ت ي ج ة ه ذ ا ا ل ر ب ع ب و ا ق ع و ب د خ و ل ا ل م ب ا ر ا ة ف ي ف ت ر ت ه ا ا ل ر ا ب ع ة و ا ل ح ا س م ة و ا ص ل ل ا ع ب و ا ل و ص ل ا س ت ث م ا ر ت س ر ع ل ا ع ب ي ا ل ش ب ا ب ف ي ا ن ه ا ء ا ل ه ج م ا ت م ا م ك ن ه م م ن م و ا ص ل ة ت ع ز ي ز ا ل ف ا ر ق و ر س م ط ر ي ق ا ل ف و ز ب ح س م ه م ل ن ت ي ج ة ه ذ ا ا ل ر ب ع ب و ا ق ع ع ب ر ت ا ل ق ا ل د و ل ي ر ا ش د ن ا ص ر ا ل ذ ي ح ص د ل ق ب ا ف ض ل م س ج ل ف ي ا ل م ب ا ر ا ة ب ر ص ي د ن ق ط ة
ح ز ا م ا ل ب ط ن
و ت س ت م ر ا ل ش ا ب ة ف ي ع ل ا ج ه ا و ت م ك ن ا ل ا ط ب ا ء ح ت ى ا ل ا ن ف ي م س ا ع د ت ه ا ع ل ى ع د م ت ن ا و ل ا ي ة ق ط ع ة ص ا ب و ن م ن ذ س ب ت م ب ر ا ل م ا ض ي
و ف ي ه ذ ا ا ل س ي ا ق ا ب د ت ه ي ى ة ا ل ا م ا ر ا ت ل ل ه و ي ة ا س ت ع د ا د ه ا ا ل د ا ى م ل ت و ف ي ر ا ل ت ق ا ر ي ر ا ل م خ ت ل ف ة ع ن س ك ا ن ا ل ا م ا ر ة و ت و ف ي ر ا ل ت و ج ي ه ا ل م ن ا س ب ح س ب ا ل م ن ا ط ق ا ل م خ ت ل ف ة ل ت و ف ي ر ا ل د ع م ا ل ف ن ي ل ت ح ق ي ق ا ل ت ز ا م ا ت ه ي ى ة ت ن م ي ة ا ل م ج ت م ع ا ل ى ج ا ن ب ا ي ج ا د ا ل ي ا ت ا ل ك ت ر و ن ي ة ت س ه ل ع م ل ي ة ت ب ا د ل و ت ح د ي ث ا ل ب ي ا ن ا ت ا ل ا ج ت م ا ع ي ة ب م ا ي ض م ن ا ل ت ع ا م ل ا ل س ه ل و س ر ي ة و خ ص و ص ي ة ب ي ا ن ا ت ا ل م ت ع ا م ل ي ن م ن ا ل ا ف ر ا د و ا ل ج ه ا ت ا ل ح ك و م ي ة و غ ي ر ا ل ح ك و م ي ة
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-04 22:55:06.681977 for dataset news_dataset
####################################################################################################
####################################################################################################
Samples Count: 2,784,041
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 31
####################################################################################################
####################################################################################################
All Tokens Count: 663,795,934
####################################################################################################
####################################################################################################
vocab/tokens: 0.0000
####################################################################################################
####################################################################################################
Tokens Entropy: 4.2503
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset news_dataset at 2023-03-04 22:56:13.924383
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-04 22:56:13.924414 for dataset news_dataset
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:

و م ع د ح و ل ا ل م ٮ ا ر ا ه ڡ ى س و ط ه ا ا ل ٮ ا ں ى ا ں ٮ ڡ ص ا ل و ص ل م ں ك ٮ و ٮ ه م ں ح ل ا ل ا ع ٮ م ا د م د ر ٮ ه ا ل م ٯ د و ں ى ى و ر د ا ں ك و د ى ڡ ى د ٮ ا ك و ڡ ع ل ى ا س ل و ٮ ا ل د ڡ ا ع ا ل ص ا ع ط ا ل د ى ا ٮ ا ح م ك ں ل ا ع ٮ ى ه م ں ا ى ٯ ا ڡ ح ط و ر ه ا ل س ٮ ا ٮ م ں ه ى ا ا ل ر ٮ ع ا ل ٮ ا ل ٮ ل م ص ل ح ٮ ه ٮ ڡ ا ر ٯ س ٮ ں ٯ ا ط و ٮ ں ٮ ى ح ه ٮ ں ى ل ا ل ڡ ر ى ٯ ا ل ا ص ڡ ر ا ل ا ڡ ص ل ى ه ٮ ں ٮ ى ح ه ه د ا ا ل ر ٮ ع ٮ و ا ٯ ع و ٮ د ح و ل ا ل م ٮ ا ر ا ه ڡ ى ڡ ٮ ر ٮ ه ا ا ل ر ا ٮ ع ه و ا ل ح ا س م ه و ا ص ل ل ا ع ٮ و ا ل و ص ل ا س ٮ ٮ م ا ر ٮ س ر ع ل ا ع ٮ ى ا ل س ٮ ا ٮ ڡ ى ا ں ه ا ء ا ل ه ح م ا ٮ م ا م ك ں ه م م ں م و ا ص ل ه ٮ ع ر ى ر ا ل ڡ ا ر ٯ و ر س م ط ر ى ٯ ا ل ڡ و ر ٮ ح س م ه م ل ں ٮ ى ح ه ه د ا ا ل ر ٮ ع ٮ و ا ٯ ع ع ٮ ر ٮ ا ل ٯ ا ل د و ل ى ر ا س د ں ا ص ر ا ل د ى ح ص د ل ٯ ٮ ا ڡ ص ل م س ح ل ڡ ى ا ل م ٮ ا ر ا ه ٮ ر ص ى د ں ٯ ط ه
ح ر ا م ا ل ٮ ط ں
و ٮ س ٮ م ر ا ل س ا ٮ ه ڡ ى ع ل ا ح ه ا و ٮ م ك ں ا ل ا ط ٮ ا ء ح ٮ ى ا ل ا ں ڡ ى م س ا ع د ٮ ه ا ع ل ى ع د م ٮ ں ا و ل ا ى ه ٯ ط ع ه ص ا ٮ و ں م ں د س ٮ ٮ م ٮ ر ا ل م ا ص ى
و ڡ ى ه د ا ا ل س ى ا ٯ ا ٮ د ٮ ه ى ى ه ا ل ا م ا ر ا ٮ ل ل ه و ى ه ا س ٮ ع د ا د ه ا ا ل د ا ى م ل ٮ و ڡ ى ر ا ل ٮ ٯ ا ر ى ر ا ل م ح ٮ ل ڡ ه ع ں س ك ا ں ا ل ا م ا ر ه و ٮ و ڡ ى ر ا ل ٮ و ح ى ه ا ل م ں ا س ٮ ح س ٮ ا ل م ں ا ط ٯ ا ل م ح ٮ ل ڡ ه ل ٮ و ڡ ى ر ا ل د ع م ا ل ڡ ں ى ل ٮ ح ٯ ى ٯ ا ل ٮ ر ا م ا ٮ ه ى ى ه ٮ ں م ى ه ا ل م ح ٮ م ع ا ل ى ح ا ں ٮ ا ى ح ا د ا ل ى ا ٮ ا ل ك ٮ ر و ں ى ه ٮ س ه ل ع م ل ى ه ٮ ٮ ا د ل و ٮ ح د ى ٮ ا ل ٮ ى ا ں ا ٮ ا ل ا ح ٮ م ا ع ى ه ٮ م ا ى ص م ں ا ل ٮ ع ا م ل ا ل س ه ل و س ر ى ه و ح ص و ص ى ه ٮ ى ا ں ا ٮ ا ل م ٮ ع ا م ل ى ں م ں ا ل ا ڡ ر ا د و ا ل ح ه ا ٮ ا ل ح ك و م ى ه و ع ى ر ا ل ح ك و م ى ه
####################################################################################################
####################################################################################################
Undotted Samples Count: 2,784,041
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 19
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 663,795,934
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0000
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 3.8467
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 12
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset news_dataset at 2023-03-04 23:32:59.881635
####################################################################################################
