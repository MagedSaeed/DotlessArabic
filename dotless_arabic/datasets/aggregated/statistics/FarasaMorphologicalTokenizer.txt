####################################################################################################
Process the Dataset
####################################################################################################
####################################################################################################
Tokenize the Dataset with FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Some of the Dataset Samples before collecting statistics:
بسم الله ال رحمن ال رحيم
ال حمد ل الله رب ال عالم ين
ال رحمن ال رحيم
مالك يوم ال دين
اياك نعبد و اياك نستعين
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Started at 2023-03-27 11:25:55.804919 for dataset aggregated_dataset tokenized by FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Samples Count: 15,779,363
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 1,413,437
####################################################################################################
####################################################################################################
All Tokens Count: 646,603,301
####################################################################################################
####################################################################################################
vocab/tokens: 0.0022
####################################################################################################
####################################################################################################
Tokens Entropy: 9.0633
####################################################################################################
####################################################################################################
Average tokens length: 7.1359
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 5.4821
####################################################################################################
####################################################################################################
Dotted Statistics Analysis Finished for dataset aggregated_dataset tokenized by FarasaMorphologicalTokenizer at 2023-03-27 11:27:49.200055
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Started at 2023-03-27 11:27:49.200092 for dataset aggregated_dataset tokenized by FarasaMorphologicalTokenizer
####################################################################################################
####################################################################################################
Undotting Dataset
####################################################################################################
####################################################################################################
Create an undotted tokens frequency mapping and save it to a json file
####################################################################################################
####################################################################################################
Some of the Dataset Samples after undotting:
ٮسم الله ال رحمں ال رحٮم
ال حمد ل الله رٮ ال عالم ٮں
ال رحمں ال رحٮم
مالك ٮوم ال دٮں
اٮاك ٮعٮد و اٮاك ٮسٮعٮں
####################################################################################################
####################################################################################################
Unique Vocabulary Count: 1,061,481
####################################################################################################
####################################################################################################
All Undotted Tokens Count: 646,603,301
####################################################################################################
####################################################################################################
undotted vocab/undotted tokens: 0.0016
####################################################################################################
####################################################################################################
Undotted Tokens Entropy: 8.7109
####################################################################################################
####################################################################################################
Average tokens length: 7.6573
####################################################################################################
####################################################################################################
Top 0.1% average tokens length: 5.8747
####################################################################################################
####################################################################################################
dotted voacb - undotted vocab: 351,956
####################################################################################################
####################################################################################################
Undotted Statistics Analysis Finished for dataset aggregated_dataset tokenized by FarasaMorphologicalTokenizer at 2023-03-27 12:09:52.014831
####################################################################################################
